{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Practicing Web Scraping with XPath\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "*After this lesson, you will be able to:*\n",
    "- Practice scraping basics\n",
    "- Review HTML and XPath basics\n",
    "- Practice scraping a website for various data and put this into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Review of HTML and web scraping](#review1)\n",
    "- [Review of XPath](#review2)\n",
    "- [Basic XPath expressions](#basic-xpath)\n",
    "    - [Absolute references](#absolute-references)\n",
    "    - [Relative references](#relative-references)\n",
    "    - [Selecting attributes](#attributes)\n",
    "- [Guided practice: Where's Waldo - \"XPath Edition\"](#practice1)\n",
    "- [1 vs. N selections](#1vsn)\n",
    "    - [Selecting the first element in a series of elements](#first-elem)\n",
    "    - [Selecting the last element in a series of elements](#last-elem)\n",
    "    - [Selecting all elements matching a selection](#all-elem-match)\n",
    "    - [Selecting elements matching an attribute](#elem-match-attr)\n",
    "- [Guided practice: selecting elements](#practice2)\n",
    "- [A quick note: the requests module](#requests)\n",
    "- [Guided practice: scrape Data Tau headlines](#practice3)\n",
    "- [Independent practice](#independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review1'></a>\n",
    "## Review of HTML and web scraping\n",
    "\n",
    "---\n",
    "\n",
    "Web scraping is a technique of extracting information from websites. It is the download and transformation of unstructured data on the web into structured data that can be stored and analyzed.\n",
    "\n",
    "There are a variety of ways to \"scrape\" what we want from the web:\n",
    "- 3rd Party Services (import.io)\n",
    "- Write our own Python apps that pull HTML documents and parse them\n",
    "  - Mechanize\n",
    "  - Scrapy\n",
    "  - Requests\n",
    "  - libxml / XPath\n",
    "  - Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Check:** What is hardest to understand about scraping?\n",
    "\n",
    "_ie: If you were asked to scrape craigslist property listings and put them in a DataFrame(), what would hold you up?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: HTML\n",
    "\n",
    "In the HTML DOM (Document Object Model), everything is a node:\n",
    " * The document itself is a document node.\n",
    " * All HTML elements are element nodes.\n",
    " * All HTML attributes are attribute nodes.\n",
    " * Text inside HTML elements are text nodes.\n",
    " * Comments are comment nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: elements\n",
    "Elements begin and end with **open and close \"tags\"**, which are defined by namespaced, encapsulated strings. \n",
    "\n",
    "```html\n",
    "<title>I am a title.</title>\n",
    "<p>I am a paragraph.</p>\n",
    "<strong>I am bold.</strong>\n",
    "```\n",
    "\n",
    "_note: the tags **title, p, and strong** are represented here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: element parent / child relationships\n",
    "\n",
    "<img src=\"http://www.htmlgoodies.com/img/2007/06/flowChart2.gif\" width=\"250\">\n",
    "\n",
    "**Elements begin and end in the same namespace like so:**  `<p></p>`\n",
    "\n",
    "**Elements can have parents and children:**\n",
    "\n",
    "```html\n",
    "<body>\n",
    "    <div>I am inside the parent element\n",
    "        <div>I am inside a child element</div>\n",
    "        <div>I am inside another child element</div>\n",
    "        <div>I am inside yet another child element</div>\n",
    "    </div>\n",
    "</body>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: element attributes\n",
    "\n",
    "Elements can also have attributes!  Attributes are defined inside **element tags** and can contain data that may be useful to scrape.\n",
    "\n",
    "```html\n",
    "<a href=\"http://lmgtfy.com/?q=html+element+attributes\" title=\"A title\" id=\"web-link\" name=\"hal\">A Simple Link</a>\n",
    "```\n",
    "\n",
    "The **element attributes** of this `<a>` tag element are:\n",
    "- id\n",
    "- href\n",
    "- title\n",
    "- name\n",
    "\n",
    "This `<a>` tag example will render in your browser like this:\n",
    "> <a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">A Simple Link</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** Can you identify an attribute, an element, a text item, and a child element?\n",
    "\n",
    "```HTML\n",
    "<html>\n",
    "   <title id=\"main-title\">All this scraping is making me itch!</title>\n",
    "   <body>\n",
    "       <h1>Welcome to my Homepage</h1>\n",
    "       <p id=\"welcome-paragraph\" class=\"strong-paragraph\">\n",
    "           <span>Hello friends, let me tell you about this cool hair product..</span>\n",
    "           <ul>\n",
    "              <li>It's cool</li>\n",
    "              <li>It's fresh</li>\n",
    "              <li>It can tell the future</li>\n",
    "              <li>Always be closing</li>\n",
    "           </ul>\n",
    "       </p>\n",
    "   </body>\n",
    "```\n",
    "\n",
    "**Bonus: What's missing?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review2'></a>\n",
    "## Review of XPath\n",
    "\n",
    "---\n",
    "\n",
    "XPath uses path expressions to select nodes or node-sets in an HTML/XML document. These path expressions look very much like the expressions you see when you work with a traditional computer file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XPath features\n",
    "\n",
    "XPath includes over 100 built-in functions to help us select and manipulate HTML (or XML) documents. XPath has functions for:\n",
    "\n",
    "- string values\n",
    "- numeric values\n",
    "- date and time comparison\n",
    "- sequence manipulation\n",
    "- Boolean values\n",
    "- and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basic-xpath'></a>\n",
    "## Basic XPath expressions\n",
    "\n",
    "---\n",
    "\n",
    "XPath comes with a wide array of features but the basics of selecting data are the most common problems that XPath can help you solve.\n",
    "\n",
    "The most common task you'll use **XPath** for is selecting data from HTML documents.  There are two ways you can **select elements** within HTML using **XPath**:\n",
    "\n",
    "- Absolute reference\n",
    "- Relative reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='absolute'></a>\n",
    "### Absolute references\n",
    "\n",
    "> _For our XPath demonstration, we will use Scrapy, which is using libxml under the hood.  Libxml provides the basic functionality for XPath expressions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'good']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install scrapy\n",
    "# pip install --upgrade zope2\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <span id=\"only-span\">good</span>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "# The same thing but \"absolute\" reference\n",
    "Selector(text=HTML).xpath('/html/body/span/text()').extract()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='relative-references'></a>\n",
    "### Relative references\n",
    "\n",
    "Relative references in XPath match the \"ends\" of structures.  Since there is only a single \"span\" element, `//span/text()` matches **one element**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'good']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='attributes'></a>\n",
    "### Selecting attributes\n",
    "\n",
    "Attributes **within a tag**, such as `id=\"only-span\"` within our span attribute.  We can get the attribute by using `@` symbol **after** the **element reference**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'only-span']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span/@id').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice1'></a>\n",
    "## Guided practice: Where's Waldo - \"XPath Edition\"\n",
    "\n",
    "---\n",
    "\n",
    "**In this example, we will find Waldo together.  Find Waldo as an:**\n",
    "\n",
    "- Element\n",
    "- Attribute\n",
    "- Text element\n",
    "\n",
    "The practice HTML string is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        \n",
    "        <ul id=\"waldo\">\n",
    "            <li class=\"waldo\">\n",
    "                <span> yo Im not here</span>\n",
    "            </li>\n",
    "            <li class=\"waldo\">Height:  ???</li>\n",
    "            <li class=\"waldo\">Weight:  ???</li>\n",
    "            <li class=\"waldo\">Last Location:  ???</li>\n",
    "            <li class=\"nerds\">\n",
    "                <div class=\"alpha\">Bill gates</div>\n",
    "                <div class=\"alpha\">Zuckerberg</div>\n",
    "                <div class=\"beta\">Theil</div>\n",
    "                <div class=\"animal\">parker</div>\n",
    "            </li>\n",
    "        </ul>\n",
    "        \n",
    "        <ul id=\"tim\">\n",
    "            <li class=\"tdawg\">\n",
    "                <span>yo im here</span>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <li>stuff</li>\n",
    "        <li>stuff2</li>\n",
    "        \n",
    "        <div id=\"cooldiv\">\n",
    "            <span class=\"dsi-rocks\">\n",
    "               YO!\n",
    "            </span>\n",
    "        </div>\n",
    "        \n",
    "        \n",
    "        <waldo>Waldo</waldo>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'waldo',\n",
       " u'waldo',\n",
       " u'waldo',\n",
       " u'waldo',\n",
       " u'nerds',\n",
       " u'alpha',\n",
       " u'alpha',\n",
       " u'beta',\n",
       " u'animal',\n",
       " u'tdawg',\n",
       " u'dsi-rocks']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//@class').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Waldo']\n",
      "[u'\\n                ', u'\\n            ', u'Height:  ???', u'Weight:  ???', u'Last Location:  ???', u'\\n                ', u'\\n                ', u'\\n                ', u'\\n                ', u'\\n            ', u'\\n                ', u'\\n            ']\n",
      "[u'<li class=\"waldo\">\\n                <span> yo Im not here</span>\\n            </li>', u'<li class=\"waldo\">Height:  ???</li>', u'<li class=\"waldo\">Weight:  ???</li>', u'<li class=\"waldo\">Last Location:  ???</li>', u'<li class=\"nerds\">\\n                <div class=\"alpha\">Bill gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">parker</div>\\n            </li>', u'<li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>', u'<li>stuff</li>', u'<li>stuff2</li>']\n",
      "[u'waldo', u'waldo', u'waldo', u'waldo', u'nerds', u'alpha', u'alpha', u'beta', u'animal', u'tdawg', u'dsi-rocks']\n",
      "[u'waldo', u'tim']\n"
     ]
    }
   ],
   "source": [
    "# Find absolute element\n",
    "print Selector(text=HTML).xpath('/html/body/waldo/text()').extract()\n",
    "print Selector(text=HTML).xpath('/html/body/ul/li/text()').extract()\n",
    "\n",
    "# Find relative element\n",
    "print Selector(text=HTML).xpath('//li').extract()\n",
    "\n",
    "# Find element attribute\n",
    "print Selector(text=HTML).xpath('////@class').extract()\n",
    "print Selector(text=HTML).xpath('//ul/@id').extract()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1vsn'></a>\n",
    "## 1 vs N selections\n",
    "\n",
    "---\n",
    "\n",
    "When selecting elements via relative reference, it's possible that you will select multiple items.  It's still possible to select single items, if you're specfic enough.\n",
    "\n",
    "**Singular Reference**\n",
    "- **Index** starts at **1**\n",
    "- Selections by offset\n",
    "- Selections by \"first\" or \"last\"\n",
    "- Selections by **unique attribute value**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'5,233.42']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "    \n",
    "        <!-- Search Results -->\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=751hUX_q0Do\" title=\"Rappin with Gas\">Rapping with gas</a>\n",
    "           <span class=\"link-details\">This is a great video about gas.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=97byWqi-zsI\" title=\"Casio Rapmap\">The Rapmaster</a>\n",
    "           <span class=\"link-details\">My first synth ever.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=TSwqnR327fk\" title=\"Cinco Products\">Cinco Midi Organizer</a>\n",
    "           <span class=\"link-details\">Midi files at the speed of light.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=8TCxE0bWQeQ\" title=\"Baddest Gates\">BBG Baddest Moments</a>\n",
    "           <span class=\"link-details\">It's tough to be a gangster.</span>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Page stats -->\n",
    "        <div class=\"page-stats-container\">\n",
    "            <li class=\"item\" id=\"pageviews\">1,333,443</li>\n",
    "            <li class=\"item\" id=\"somethingelse\">bla</li>\n",
    "            <li class=\"item\" id=\"last-viewed\">01-22-2016</li>\n",
    "            <li class=\"item\" id=\"views-per-hour\">1,532</li>\n",
    "            <li class=\"item\" id=\"kiefer-views-per-hour\">5,233.42</li>\n",
    "        </div>\n",
    "        \n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "span = Selector(text=HTML).xpath('/html/body/div/li[@id=\"kiefer-views-per-hour\"]/text()').extract()\n",
    "span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='first-elem'></a>\n",
    "### Selecting the first element in a series of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<span class=\"link-details\">This is a great video about gas.</span>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = Selector(text=HTML).xpath('//span').extract()\n",
    "spans[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='last-elem'></a>\n",
    "### Selecting the last element in a series of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<span class=\"link-details\">It\\'s tough to be a gangster.</span>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = Selector(text=HTML).xpath('//span').extract()\n",
    "spans[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='all-elem-match'></a>\n",
    "### Selecting all elements matching a selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'<span class=\"link-details\">This is a great video about gas.</span>',\n",
       " u'<span class=\"link-details\">My first synth ever.</span>',\n",
       " u'<span class=\"link-details\">Midi files at the speed of light.</span>',\n",
       " u'<span class=\"link-details\">It\\'s tough to be a gangster.</span>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='elem-match-attr'></a>\n",
    "### Selecting elements matching an _attribute_\n",
    "\n",
    "This will be one of the most common ways you will select items.  HTML DOM elements will be more differentiated based on their \"class\" and \"id\" variables.  Mainly, these types of attributes are used by web developers to refer to specfic elements or a broad set of elements to apply visual characteristics using CSS.\n",
    "\n",
    "```HTML \n",
    "//element[@attribute=\"value\"]\n",
    "```\n",
    "\n",
    "**Generally**\n",
    "\n",
    "- \"class\" attributes within elements usually refer to multiple items\n",
    "- \"id\" attributes are supposed to be unique, but not always\n",
    "\n",
    "_CSS stands for cascading style sheets.  These are used to abstract the definition of visual elements on a micro and macro scale for the web.  They are also our best friend as data miners.  They give us strong hints and cues as to how a web document is structured._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice2'></a>\n",
    "## Guided practice: selecting elements\n",
    "\n",
    "---\n",
    "\n",
    "1. **How can we get a series of only text items for the page statistics section of our page?**\n",
    "2. **We want to know only how many times Kiefer views my Youtube videos page per hour?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='//li/text()' data=u'1,333,443'>,\n",
       " <Selector xpath='//li/text()' data=u'bla'>,\n",
       " <Selector xpath='//li/text()' data=u'01-22-2016'>,\n",
       " <Selector xpath='//li/text()' data=u'1,532'>,\n",
       " <Selector xpath='//li/text()' data=u'5,233.42'>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all text elements for the page statistics section\n",
    "Selector(text=HTML).xpath('//li/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'5,233.42']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the text for \"Kiefer's\" number of views per hour\n",
    "# Selector(text=HTML).xpath('//div[@class=\"page-stats-container\"]/li[4]/text()').extract()\n",
    "\n",
    "# Get only the text for \"Kiefer's\" number of views per hour\n",
    "Selector(text=HTML).xpath('//li[@id=\"kiefer-views-per-hour\"]/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "## A quick note:  the `requests` module\n",
    "\n",
    "---\n",
    "\n",
    "The requests module is the gateway to interacting with the web using Python.  We can:\n",
    "\n",
    " - Fetch web documents as strings\n",
    " - Decode JSON\n",
    " - Basic data munging with Web Documents\n",
    " - Download static files that are not text\n",
    "  - Images\n",
    "  - Videos\n",
    "  - Binary data\n",
    "\n",
    "\n",
    "Take some time and read up on Requests:\n",
    "\n",
    "http://docs.python-requests.org/en/master/user/quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice3'></a>\n",
    "## Guided practice: scrape Data Tau headlines\n",
    "\n",
    "DataTau is a great site for data science news. Let's take their headlines using Python **`requests`**, and practice selecting various elements.\n",
    "\n",
    "Using <a href=\"https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=en\">XPath helper Chrome plugin</a> _(cmd-shift-x)_ and the Chrome \"inspect\" feature, let's explore the structure of the page.\n",
    "\n",
    "_Here's a <a href=\"https://www.youtube.com/watch?v=i2Li1vnv09U\">concise video</a> that demonstrates the basic inspect feature within Chrome._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<html><head><link rel=\"stylesheet\" type=\"text/css\" href=\"news.css\">\\n<link rel=\"shortcut icon\" href=\"http://www.iconj.com/ico/d/x/dxo02ap56v.ico\">\\n<scr'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please only run this frame once to avoid hitting the site too hard all at once\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"http://www.datatau.com\")\n",
    "HTML = response.text  \n",
    "HTML[0:150]           # view the first 500 characters of the HTML index document for DataTau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Only The Headlines\n",
    "\n",
    "We will use the XPath helper tool to inspect the markup that comprises the **title** to find any pattern.  Since there are more than one **titles**, we expect to find a series of elements representing the **title** data that we are interested in.\n",
    "\n",
    "![](https://snag.gy/m4K3UE.jpg)\n",
    "\n",
    "In this example, we are referencing the the **1st center**, **3rd table row (`tr[3]`)**, within the 2nd **td having a class of \"title\" (`td[@class=\"title\"][2]`)**, and the anchor tag within a **(`a/text()`)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Intro to a ML algorithm that tends to fly below the radar: Self-Organizing Maps',\n",
       " u'Interview questions for data scientists',\n",
       " u'A list of must read books for Data Science',\n",
       " u'How Soft Clustering for HDBSCAN Works',\n",
       " u\"What's wrong with my time series? Error measurement and validation for modeling\",\n",
       " u'How to choose a project to practice data science',\n",
       " u'The Reasonable Effectiveness of the Multiplicative Weights Update Algorithm',\n",
       " u'How to Start an R Project',\n",
       " u'Time Person of the Year\\u200a\\u2014\\u200aA snapshot of history with data',\n",
       " u'Random-Walk Bayesian Deep Networks in PyMC3']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titles = Selector(text=HTML).xpath('//td[@class=\"title\"]/a/text()').extract()\n",
    "titles[0:10] # the first 5 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we get the urls from the titles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/x?fnid=Klezik46MX',\n",
       " u'https://medium.com/athelas/paper-1-baidus-deep-voice-675a323705df#.jo8jmxx0o',\n",
       " u'https://www.mapd.com/blog/2017/03/03/the-forest-and-the-trees/',\n",
       " u'https://arxiv.org/abs/1702.08835',\n",
       " u'https://github.com/jwkvam/bowtie',\n",
       " u'https://www.neuraldesigner.com/blog/5_algorithms_to_train_a_neural_network',\n",
       " u'http://tech.marksblogg.com/tensorflow-vizdoom-bots.html',\n",
       " u'https://research.fb.com/prophet-forecasting-at-scale/',\n",
       " u'https://data36.com/command-line-data-science-introduction-to-bash/',\n",
       " u'https://blog.godatadriven.com/how-to-start-a-data-science-project-in-python',\n",
       " u'https://danidelvalle.me/2017/03/09/engaging-your-audience-with-email-attractive-contents-mjml-jinja2-owncloud-airflow/',\n",
       " u'https://blog.wikimedia.org/2017/02/02/hiring-data-scientist/',\n",
       " u'https://developers.googleblog.com/2017/03/xla-tensorflow-compiled.html',\n",
       " u'https://medium.com/@kacawi/ipython-or-jupyter-10a9fb82682b',\n",
       " u'https://arxiv.org/abs/1702.05243',\n",
       " u'https://blog.dominodatalab.com/fitting-gaussian-process-models-python/',\n",
       " u'https://techcrunch.com/2017/03/07/google-is-acquiring-data-science-community-kaggle/',\n",
       " u'https://blog.alookanalytics.com/2017/03/08/8-simple-ways-how-to-boost-your-coding-skills-not-just-in-r/',\n",
       " u'https://github.com/yandexdataschool/Practical_RL',\n",
       " u'http://algorithms-tour.stitchfix.com/',\n",
       " u'http://cooldatasets.com/',\n",
       " u'http://twiecki.github.io/blog/2017/03/14/random-walk-deep-net/',\n",
       " u'https://medium.com/learning-machine-learning/time-person-of-the-year-a-snapshot-of-history-with-data-cab63926e1a2#.abp9sh1wi',\n",
       " u'https://blog.datazar.com/how-to-start-an-r-project-8501819634d4#.yuofoes20',\n",
       " u'https://jeremykun.com/2017/02/27/the-reasonable-effectiveness-of-the-multiplicative-weights-update-algorithm/',\n",
       " u'http://sharpsightlabs.com/blog/choose-project-practice-data-science/',\n",
       " u'https://blog.insightdatascience.com/whats-wrong-with-my-time-series-model-validation-without-a-hold-out-set-94151d38cf5b#.jwy7xgvxc',\n",
       " u'http://hdbscan.readthedocs.io/en/latest/soft_clustering_explanation.html',\n",
       " u'http://blog.paralleldots.com/data-scientist/list-must-read-books-data-science/',\n",
       " u'https://shapescience.xyz/blog/interview-questions-for-data-scientists/',\n",
       " u'http://blog.yhat.com/posts/self-organizing-maps-1.html']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = Selector(text=HTML).xpath('//td[@class=\"title\"]/a/@href').extract()\n",
    "urls[::-1]\n",
    "#<a href=\"http://tech.marksblogg.com/faster-queries-google-cloud-dataproc.html\">33x Faster Queries on Google Cloud's Dataproc using Facebook's Presto</a>\n",
    "# titles[0:5] # the first 5 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we get the site domain, after the title within the parentheses (ie: stitchfix.com)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domains = Selector(text=HTML).xpath(\"//span[@class='comhead']/text()\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u' (yhat.com) ',\n",
       " u' (shapescience.xyz) ',\n",
       " u' (paralleldots.com) ',\n",
       " u' (readthedocs.io) ',\n",
       " u' (insightdatascience.com) ']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about the points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'2 points', u'3 points', u'4 points', u'3 points', u'5 points']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = Selector(text=HTML).xpath('//td[@class=\"subtext\"]/span/text()').extract()\n",
    "points[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about the \"more Link?\"\n",
    "\n",
    "> *Hint:  You can use `element[text()='exact text']` to find text element matching specific text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/x?fnid=Klezik46MX']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_link = Selector(text=HTML).xpath('//a[text()=\"More\"]/@href').extract()\n",
    "next_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='independent'></a>\n",
    "## Independent practice\n",
    "\n",
    "---\n",
    "\n",
    "**For the next 30 minutes try to grab the following from Data Tau:**\n",
    "\n",
    "- Story titles\n",
    "- Story URL (href)\n",
    "- Domain\n",
    "- Points\n",
    "\n",
    "**Stretch goals:**\n",
    "- Author\n",
    "- Comment count\n",
    "\n",
    "**Put your results into a DataFrame.**\n",
    "\n",
    "- Do basic analysis of domains and point distributions\n",
    "\n",
    "**BONUS:**\n",
    "\n",
    "Automatically find the next \"more link\" and mine the next page(s) until none exist.  Logically, you can each page with this pseudo code:\n",
    "\n",
    "1. Does the next link exist (a tag with text == \"More\")\n",
    "- Fetch URL, prepended with domain (datatau.com/(extracted link here))\n",
    "- Parse the page with `Selector(text=HTML).xpath('').extract()` to find the elements\n",
    "- Add to dataframe\n",
    "\n",
    "> _Note:  You might want to set a limit something like 2-3 total requests per attempt to avoid unecessary transfer._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching http://www.datatau.com/x?fnid=fbPGCFcLTR...\n",
      "Fetching http://www.datatau.com/x?fnid=Z4S9nfYSrS...\n",
      "Fetching http://www.datatau.com/x?fnid=VEPViKgvLb...\n",
      "Fetching http://www.datatau.com/x?fnid=z6xLOvZJiq...\n",
      "Fetching http://www.datatau.com/x?fnid=3djUUHgo25...\n",
      "Fetching http://www.datatau.com/x?fnid=HZM6VjkHf9...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>authors</th>\n",
       "      <th>comments</th>\n",
       "      <th>domains</th>\n",
       "      <th>links</th>\n",
       "      <th>points</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sscgovt</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(sscgovt.in)</td>\n",
       "      <td>http://sscgovt.in/ssc-cgl/</td>\n",
       "      <td>2 points</td>\n",
       "      <td>SSC CGL 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>philipcdavis</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(learningd3.com)</td>\n",
       "      <td>https://learningd3.com/blog/how-to-pick-colors...</td>\n",
       "      <td>18 points</td>\n",
       "      <td>How to Pick Colors for Your Data Visualizations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>kawica</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/@kacawi/python-machine-lear...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>Scikit-learn Tutorial For Beginners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ejwk</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(nytimes.com)</td>\n",
       "      <td>http://www.nytimes.com/2016/12/14/magazine/the...</td>\n",
       "      <td>25 points</td>\n",
       "      <td>The Great A.I. Awakening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>flovv</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>http://flovv.github.io/MachineLearning_Improve...</td>\n",
       "      <td>11 points</td>\n",
       "      <td>The Instant Rise of Machine Intelligence?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>verkter</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(openai.com)</td>\n",
       "      <td>https://openai.com/blog/GTA-V-plus-Universe/</td>\n",
       "      <td>4 points</td>\n",
       "      <td>GTA V plus Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>jasdumas</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>https://jasdumas.github.io/2017-01-04-choosing...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Explaining Statistical Goodness of fit Tests w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>jast</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(dennybritz.com)</td>\n",
       "      <td>http://blog.dennybritz.com/2017/01/17/engineer...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Engineering is the bottleneck in deep learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>lettier</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>https://lettier.github.io/posts/2017-01-15-lin...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Simple Linear Regression from scratch using Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>gradientflow</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(oreilly.com)</td>\n",
       "      <td>https://www.oreilly.com/ideas/how-big-compute-...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>How big compute is powering the deep learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ejwk</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(theguardian.com)</td>\n",
       "      <td>https://www.theguardian.com/technology/2016/de...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>World’s largest hedge fund to replace managers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>itdxer3</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(neupy.com)</td>\n",
       "      <td>http://neupy.com/2016/12/17/hyperparameter_opt...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Hyperparameter optimization for Neural Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>bull</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(drivendata.org)</td>\n",
       "      <td>https://www.drivendata.org/competitions/44/</td>\n",
       "      <td>9 points</td>\n",
       "      <td>ML Competition: Predict the Spread of Dengue F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>benfrederickson</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/@karpathy/yes-you-should-un...</td>\n",
       "      <td>15 points</td>\n",
       "      <td>Yes you should understand backprop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>jeffheaton</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(heatonresearch.com)</td>\n",
       "      <td>http://www.heatonresearch.com/2017/01/01/tenso...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Using a Win SurfaceBook GPU cut 2 hour trainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>dwhitena</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/pachyderm-data/jupyter-pach...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Exploring and Understanding Historical Analyses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>jerryboey</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(pocketcluster.wordpress.com)</td>\n",
       "      <td>item?id=16160</td>\n",
       "      <td>7 points</td>\n",
       "      <td>Online data analysis test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>stkim1</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(datascienceresume.com)</td>\n",
       "      <td>https://pocketcluster.wordpress.com/2016/12/29...</td>\n",
       "      <td>7 points</td>\n",
       "      <td>BigData and ML Library and Framework Weekly Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Sunbite</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(doingdata.org)</td>\n",
       "      <td>http://datascienceresume.com/advice/how-should...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>How should a Data Scientist's resume differ fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>ashishyoungy</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(technical.ly)</td>\n",
       "      <td>https://www.doingdata.org/blog/how-to-create-a...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>How to Create a Funnel Chart in Tableau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>tfturing</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>http://technical.ly/brooklyn/2016/06/08/fred-b...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>‘Mathwashing,’ Facebook and the zeitgeist of d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>rishy</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(learningd3.com)</td>\n",
       "      <td>http://rishy.github.io/ml/2017/01/05/how-to-tr...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>How to train your Deep Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>philipcdavis</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(jeannicholashould.com)</td>\n",
       "      <td>https://learningd3.com</td>\n",
       "      <td>17 points</td>\n",
       "      <td>Learning D3: A course on building data visuali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>nickhould</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(plot.ly)</td>\n",
       "      <td>http://www.jeannicholashould.com/tidy-data-in-...</td>\n",
       "      <td>24 points</td>\n",
       "      <td>Tidy Data in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>pdsh</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(posthaven.com)</td>\n",
       "      <td>https://plot.ly/~jackp/16209/machine-learning-...</td>\n",
       "      <td>14 points</td>\n",
       "      <td>Machine Learning Classifier Comparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>jcbozonier</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(labri.fr)</td>\n",
       "      <td>https://databozo.posthaven.com/the-most-boring...</td>\n",
       "      <td>19 points</td>\n",
       "      <td>The most boring/valuable data scientist advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>axelr</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(bigdatauniversity.com)</td>\n",
       "      <td>http://www.labri.fr/perso/nrougier/from-python...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Numpy book with lovely animations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>ejwk</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(datazar.com)</td>\n",
       "      <td>https://bigdatauniversity.com/courses/deep-lea...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Deep Learning with TensorFlow - free MOOC from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>ata_aman</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(herokuapp.com)</td>\n",
       "      <td>https://blog.datazar.com/notebookjs-training-a...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Training a Neural Network in JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>anon777</td>\n",
       "      <td>discuss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://way-of-life-1.herokuapp.com/graphs/e44a...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Some neat resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>elisebreda</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(yhat.com)</td>\n",
       "      <td>http://blog.yhat.com/posts/self-organizing-map...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Intro to a ML algorithm that tends to fly belo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1</td>\n",
       "      <td>aflam</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(shapescience.xyz)</td>\n",
       "      <td>https://shapescience.xyz/blog/interview-questi...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Interview questions for data scientists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2</td>\n",
       "      <td>muktabh</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(paralleldots.com)</td>\n",
       "      <td>http://blog.paralleldots.com/data-scientist/li...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>A list of must read books for Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>3</td>\n",
       "      <td>lmcinnes</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(readthedocs.io)</td>\n",
       "      <td>http://hdbscan.readthedocs.io/en/latest/soft_c...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>How Soft Clustering for HDBSCAN Works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>4</td>\n",
       "      <td>mattasmith</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(insightdatascience.com)</td>\n",
       "      <td>https://blog.insightdatascience.com/whats-wron...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>What's wrong with my time series? Error measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>5</td>\n",
       "      <td>SharpSightLabs</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(sharpsightlabs.com)</td>\n",
       "      <td>http://sharpsightlabs.com/blog/choose-project-...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>How to choose a project to practice data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>6</td>\n",
       "      <td>jackmaney</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(jeremykun.com)</td>\n",
       "      <td>https://jeremykun.com/2017/02/27/the-reasonabl...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>The Reasonable Effectiveness of the Multiplica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>7</td>\n",
       "      <td>ata_aman</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(datazar.com)</td>\n",
       "      <td>https://blog.datazar.com/how-to-start-an-r-pro...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>How to Start an R Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>8</td>\n",
       "      <td>tahsin_mayeesha</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/learning-machine-learning/t...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Time Person of the Year — A snapshot of histor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>9</td>\n",
       "      <td>twiecki</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>http://twiecki.github.io/blog/2017/03/14/rando...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Random-Walk Bayesian Deep Networks in PyMC3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>10</td>\n",
       "      <td>ata_aman</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(cooldatasets.com)</td>\n",
       "      <td>http://cooldatasets.com/</td>\n",
       "      <td>14 points</td>\n",
       "      <td>Cool Datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>11</td>\n",
       "      <td>hspter</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(stitchfix.com)</td>\n",
       "      <td>http://algorithms-tour.stitchfix.com/</td>\n",
       "      <td>12 points</td>\n",
       "      <td>Algorithms Tour: How data science is woven int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>12</td>\n",
       "      <td>axelr</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.com)</td>\n",
       "      <td>https://github.com/yandexdataschool/Practical_RL</td>\n",
       "      <td>12 points</td>\n",
       "      <td>Github course of practical reinforcement learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>13</td>\n",
       "      <td>adam_alook</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(alookanalytics.com)</td>\n",
       "      <td>https://blog.alookanalytics.com/2017/03/08/8-s...</td>\n",
       "      <td>12 points</td>\n",
       "      <td>8 simple ways how to boost your coding skills ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>14</td>\n",
       "      <td>ata_aman</td>\n",
       "      <td>5 comments</td>\n",
       "      <td>(techcrunch.com)</td>\n",
       "      <td>https://techcrunch.com/2017/03/07/google-is-ac...</td>\n",
       "      <td>13 points</td>\n",
       "      <td>Google is acquiring Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>15</td>\n",
       "      <td>yd43kl</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(dominodatalab.com)</td>\n",
       "      <td>https://blog.dominodatalab.com/fitting-gaussia...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>Fitting Gaussian Process Models in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>16</td>\n",
       "      <td>DanielleMolloy</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(arxiv.org)</td>\n",
       "      <td>https://arxiv.org/abs/1702.05243</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Estimating nonlinear dynamics with convolution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>17</td>\n",
       "      <td>kawica</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/@kacawi/ipython-or-jupyter-...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>IPython or Jupyter?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>18</td>\n",
       "      <td>richardw</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(googleblog.com)</td>\n",
       "      <td>https://developers.googleblog.com/2017/03/xla-...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>XLA - TensorFlow, compiled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>19</td>\n",
       "      <td>hgarg</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(wikimedia.org)</td>\n",
       "      <td>https://blog.wikimedia.org/2017/02/02/hiring-d...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>How Wikimedia hires Data Scientists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>20</td>\n",
       "      <td>danidelvalle</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(danidelvalle.me)</td>\n",
       "      <td>https://danidelvalle.me/2017/03/09/engaging-yo...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Engaging your audience with email attractive (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>21</td>\n",
       "      <td>hgrif</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(godatadriven.com)</td>\n",
       "      <td>https://blog.godatadriven.com/how-to-start-a-d...</td>\n",
       "      <td>19 points</td>\n",
       "      <td>How to start a Data Science project in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>22</td>\n",
       "      <td>data36</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(data36.com)</td>\n",
       "      <td>https://data36.com/command-line-data-science-i...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Data Coding 101 – Introduction To Bash – episo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>23</td>\n",
       "      <td>danning</td>\n",
       "      <td>12 comments</td>\n",
       "      <td>(fb.com)</td>\n",
       "      <td>https://research.fb.com/prophet-forecasting-at...</td>\n",
       "      <td>29 points</td>\n",
       "      <td>Announcing Prophet: A tool that provides accur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>24</td>\n",
       "      <td>marklit</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(marksblogg.com)</td>\n",
       "      <td>http://tech.marksblogg.com/tensorflow-vizdoom-...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>Training Doom Bots in TensorFlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>25</td>\n",
       "      <td>sergios</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(neuraldesigner.com)</td>\n",
       "      <td>https://www.neuraldesigner.com/blog/5_algorith...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>5 algorithms to train a neural network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>26</td>\n",
       "      <td>jwkvam</td>\n",
       "      <td>5 comments</td>\n",
       "      <td>(github.com)</td>\n",
       "      <td>https://github.com/jwkvam/bowtie</td>\n",
       "      <td>10 points</td>\n",
       "      <td>Bowtie: an interactive dashboard toolkit in py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>27</td>\n",
       "      <td>elyase</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(arxiv.org)</td>\n",
       "      <td>https://arxiv.org/abs/1702.08835</td>\n",
       "      <td>11 points</td>\n",
       "      <td>Deep Forest: Towards An Alternative to Deep Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>28</td>\n",
       "      <td>breezyday</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(mapd.com)</td>\n",
       "      <td>https://www.mapd.com/blog/2017/03/03/the-fores...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Answering unknown questions that arise from da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>29</td>\n",
       "      <td>adamonthedl</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/athelas/paper-1-baidus-deep...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Baidu Deep Voice explained: Part 1 — the Infer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index          authors     comments                          domains  \\\n",
       "0        0          sscgovt      discuss                    (sscgovt.in)    \n",
       "1        1     philipcdavis   2 comments                (learningd3.com)    \n",
       "2        2           kawica      discuss                    (medium.com)    \n",
       "3        3             ejwk    1 comment                   (nytimes.com)    \n",
       "4        4            flovv    1 comment                     (github.io)    \n",
       "5        5          verkter      discuss                    (openai.com)    \n",
       "6        6         jasdumas      discuss                     (github.io)    \n",
       "7        7             jast      discuss                (dennybritz.com)    \n",
       "8        8          lettier      discuss                     (github.io)    \n",
       "9        9     gradientflow      discuss                   (oreilly.com)    \n",
       "10      10             ejwk      discuss               (theguardian.com)    \n",
       "11      11          itdxer3      discuss                     (neupy.com)    \n",
       "12      12             bull    1 comment                (drivendata.org)    \n",
       "13      13  benfrederickson      discuss                    (medium.com)    \n",
       "14      14       jeffheaton      discuss            (heatonresearch.com)    \n",
       "15      15         dwhitena      discuss                    (medium.com)    \n",
       "16      16        jerryboey   2 comments   (pocketcluster.wordpress.com)    \n",
       "17      17           stkim1      discuss         (datascienceresume.com)    \n",
       "18      18          Sunbite      discuss                 (doingdata.org)    \n",
       "19      19     ashishyoungy      discuss                  (technical.ly)    \n",
       "20      20         tfturing      discuss                     (github.io)    \n",
       "21      21            rishy      discuss                (learningd3.com)    \n",
       "22      22     philipcdavis   2 comments         (jeannicholashould.com)    \n",
       "23      23        nickhould   2 comments                       (plot.ly)    \n",
       "24      24             pdsh      discuss                 (posthaven.com)    \n",
       "25      25       jcbozonier    1 comment                      (labri.fr)    \n",
       "26      26            axelr      discuss         (bigdatauniversity.com)    \n",
       "27      27             ejwk      discuss                   (datazar.com)    \n",
       "28      28         ata_aman      discuss                 (herokuapp.com)    \n",
       "29      29          anon777      discuss                              NaN   \n",
       "..     ...              ...          ...                              ...   \n",
       "180      0       elisebreda      discuss                      (yhat.com)    \n",
       "181      1            aflam      discuss              (shapescience.xyz)    \n",
       "182      2          muktabh      discuss              (paralleldots.com)    \n",
       "183      3         lmcinnes      discuss                (readthedocs.io)    \n",
       "184      4       mattasmith      discuss        (insightdatascience.com)    \n",
       "185      5   SharpSightLabs      discuss            (sharpsightlabs.com)    \n",
       "186      6        jackmaney      discuss                 (jeremykun.com)    \n",
       "187      7         ata_aman      discuss                   (datazar.com)    \n",
       "188      8  tahsin_mayeesha      discuss                    (medium.com)    \n",
       "189      9          twiecki      discuss                     (github.io)    \n",
       "190     10         ata_aman      discuss              (cooldatasets.com)    \n",
       "191     11           hspter      discuss                 (stitchfix.com)    \n",
       "192     12            axelr      discuss                    (github.com)    \n",
       "193     13       adam_alook      discuss            (alookanalytics.com)    \n",
       "194     14         ata_aman   5 comments                (techcrunch.com)    \n",
       "195     15           yd43kl      discuss             (dominodatalab.com)    \n",
       "196     16   DanielleMolloy      discuss                     (arxiv.org)    \n",
       "197     17           kawica      discuss                    (medium.com)    \n",
       "198     18         richardw      discuss                (googleblog.com)    \n",
       "199     19            hgarg      discuss                 (wikimedia.org)    \n",
       "200     20     danidelvalle      discuss               (danidelvalle.me)    \n",
       "201     21            hgrif      discuss              (godatadriven.com)    \n",
       "202     22           data36      discuss                    (data36.com)    \n",
       "203     23          danning  12 comments                        (fb.com)    \n",
       "204     24          marklit      discuss                (marksblogg.com)    \n",
       "205     25          sergios      discuss            (neuraldesigner.com)    \n",
       "206     26           jwkvam   5 comments                    (github.com)    \n",
       "207     27           elyase   2 comments                     (arxiv.org)    \n",
       "208     28        breezyday      discuss                      (mapd.com)    \n",
       "209     29      adamonthedl    1 comment                    (medium.com)    \n",
       "\n",
       "                                                 links     points  \\\n",
       "0                           http://sscgovt.in/ssc-cgl/   2 points   \n",
       "1    https://learningd3.com/blog/how-to-pick-colors...  18 points   \n",
       "2    https://medium.com/@kacawi/python-machine-lear...   8 points   \n",
       "3    http://www.nytimes.com/2016/12/14/magazine/the...  25 points   \n",
       "4    http://flovv.github.io/MachineLearning_Improve...  11 points   \n",
       "5         https://openai.com/blog/GTA-V-plus-Universe/   4 points   \n",
       "6    https://jasdumas.github.io/2017-01-04-choosing...   6 points   \n",
       "7    http://blog.dennybritz.com/2017/01/17/engineer...   2 points   \n",
       "8    https://lettier.github.io/posts/2017-01-15-lin...   2 points   \n",
       "9    https://www.oreilly.com/ideas/how-big-compute-...   3 points   \n",
       "10   https://www.theguardian.com/technology/2016/de...   8 points   \n",
       "11   http://neupy.com/2016/12/17/hyperparameter_opt...   2 points   \n",
       "12         https://www.drivendata.org/competitions/44/   9 points   \n",
       "13   https://medium.com/@karpathy/yes-you-should-un...  15 points   \n",
       "14   http://www.heatonresearch.com/2017/01/01/tenso...   6 points   \n",
       "15   https://medium.com/pachyderm-data/jupyter-pach...   5 points   \n",
       "16                                       item?id=16160   7 points   \n",
       "17   https://pocketcluster.wordpress.com/2016/12/29...   7 points   \n",
       "18   http://datascienceresume.com/advice/how-should...   6 points   \n",
       "19   https://www.doingdata.org/blog/how-to-create-a...   3 points   \n",
       "20   http://technical.ly/brooklyn/2016/06/08/fred-b...   5 points   \n",
       "21   http://rishy.github.io/ml/2017/01/05/how-to-tr...   3 points   \n",
       "22                              https://learningd3.com  17 points   \n",
       "23   http://www.jeannicholashould.com/tidy-data-in-...  24 points   \n",
       "24   https://plot.ly/~jackp/16209/machine-learning-...  14 points   \n",
       "25   https://databozo.posthaven.com/the-most-boring...  19 points   \n",
       "26   http://www.labri.fr/perso/nrougier/from-python...   4 points   \n",
       "27   https://bigdatauniversity.com/courses/deep-lea...   9 points   \n",
       "28   https://blog.datazar.com/notebookjs-training-a...   3 points   \n",
       "29   http://way-of-life-1.herokuapp.com/graphs/e44a...   3 points   \n",
       "..                                                 ...        ...   \n",
       "180  http://blog.yhat.com/posts/self-organizing-map...   2 points   \n",
       "181  https://shapescience.xyz/blog/interview-questi...   3 points   \n",
       "182  http://blog.paralleldots.com/data-scientist/li...   4 points   \n",
       "183  http://hdbscan.readthedocs.io/en/latest/soft_c...   3 points   \n",
       "184  https://blog.insightdatascience.com/whats-wron...   5 points   \n",
       "185  http://sharpsightlabs.com/blog/choose-project-...   4 points   \n",
       "186  https://jeremykun.com/2017/02/27/the-reasonabl...   3 points   \n",
       "187  https://blog.datazar.com/how-to-start-an-r-pro...   4 points   \n",
       "188  https://medium.com/learning-machine-learning/t...   2 points   \n",
       "189  http://twiecki.github.io/blog/2017/03/14/rando...   2 points   \n",
       "190                           http://cooldatasets.com/  14 points   \n",
       "191              http://algorithms-tour.stitchfix.com/  12 points   \n",
       "192   https://github.com/yandexdataschool/Practical_RL  12 points   \n",
       "193  https://blog.alookanalytics.com/2017/03/08/8-s...  12 points   \n",
       "194  https://techcrunch.com/2017/03/07/google-is-ac...  13 points   \n",
       "195  https://blog.dominodatalab.com/fitting-gaussia...   8 points   \n",
       "196                   https://arxiv.org/abs/1702.05243   5 points   \n",
       "197  https://medium.com/@kacawi/ipython-or-jupyter-...   9 points   \n",
       "198  https://developers.googleblog.com/2017/03/xla-...   6 points   \n",
       "199  https://blog.wikimedia.org/2017/02/02/hiring-d...   9 points   \n",
       "200  https://danidelvalle.me/2017/03/09/engaging-yo...   4 points   \n",
       "201  https://blog.godatadriven.com/how-to-start-a-d...  19 points   \n",
       "202  https://data36.com/command-line-data-science-i...   6 points   \n",
       "203  https://research.fb.com/prophet-forecasting-at...  29 points   \n",
       "204  http://tech.marksblogg.com/tensorflow-vizdoom-...   8 points   \n",
       "205  https://www.neuraldesigner.com/blog/5_algorith...   5 points   \n",
       "206                   https://github.com/jwkvam/bowtie  10 points   \n",
       "207                   https://arxiv.org/abs/1702.08835  11 points   \n",
       "208  https://www.mapd.com/blog/2017/03/03/the-fores...   5 points   \n",
       "209  https://medium.com/athelas/paper-1-baidus-deep...   2 points   \n",
       "\n",
       "                                                titles  \n",
       "0                                         SSC CGL 2017  \n",
       "1      How to Pick Colors for Your Data Visualizations  \n",
       "2                  Scikit-learn Tutorial For Beginners  \n",
       "3                             The Great A.I. Awakening  \n",
       "4            The Instant Rise of Machine Intelligence?  \n",
       "5                                  GTA V plus Universe  \n",
       "6    Explaining Statistical Goodness of fit Tests w...  \n",
       "7    Engineering is the bottleneck in deep learning...  \n",
       "8    Simple Linear Regression from scratch using Gr...  \n",
       "9    How big compute is powering the deep learning ...  \n",
       "10   World’s largest hedge fund to replace managers...  \n",
       "11     Hyperparameter optimization for Neural Networks  \n",
       "12   ML Competition: Predict the Spread of Dengue F...  \n",
       "13                  Yes you should understand backprop  \n",
       "14   Using a Win SurfaceBook GPU cut 2 hour trainin...  \n",
       "15     Exploring and Understanding Historical Analyses  \n",
       "16                           Online data analysis test  \n",
       "17   BigData and ML Library and Framework Weekly Ro...  \n",
       "18   How should a Data Scientist's resume differ fr...  \n",
       "19             How to Create a Funnel Chart in Tableau  \n",
       "20   ‘Mathwashing,’ Facebook and the zeitgeist of d...  \n",
       "21               How to train your Deep Neural Network  \n",
       "22   Learning D3: A course on building data visuali...  \n",
       "23                                 Tidy Data in Python  \n",
       "24              Machine Learning Classifier Comparison  \n",
       "25      The most boring/valuable data scientist advice  \n",
       "26                   Numpy book with lovely animations  \n",
       "27   Deep Learning with TensorFlow - free MOOC from...  \n",
       "28             Training a Neural Network in JavaScript  \n",
       "29                                 Some neat resources  \n",
       "..                                                 ...  \n",
       "180  Intro to a ML algorithm that tends to fly belo...  \n",
       "181            Interview questions for data scientists  \n",
       "182         A list of must read books for Data Science  \n",
       "183              How Soft Clustering for HDBSCAN Works  \n",
       "184  What's wrong with my time series? Error measur...  \n",
       "185   How to choose a project to practice data science  \n",
       "186  The Reasonable Effectiveness of the Multiplica...  \n",
       "187                          How to Start an R Project  \n",
       "188  Time Person of the Year — A snapshot of histor...  \n",
       "189        Random-Walk Bayesian Deep Networks in PyMC3  \n",
       "190                                      Cool Datasets  \n",
       "191  Algorithms Tour: How data science is woven int...  \n",
       "192  Github course of practical reinforcement learn...  \n",
       "193  8 simple ways how to boost your coding skills ...  \n",
       "194                         Google is acquiring Kaggle  \n",
       "195          Fitting Gaussian Process Models in Python  \n",
       "196  Estimating nonlinear dynamics with convolution...  \n",
       "197                                IPython or Jupyter?  \n",
       "198                         XLA - TensorFlow, compiled  \n",
       "199                How Wikimedia hires Data Scientists  \n",
       "200  Engaging your audience with email attractive (...  \n",
       "201      How to start a Data Science project in Python  \n",
       "202  Data Coding 101 – Introduction To Bash – episo...  \n",
       "203  Announcing Prophet: A tool that provides accur...  \n",
       "204                   Training Doom Bots in TensorFlow  \n",
       "205             5 algorithms to train a neural network  \n",
       "206  Bowtie: an interactive dashboard toolkit in py...  \n",
       "207  Deep Forest: Towards An Alternative to Deep Ne...  \n",
       "208  Answering unknown questions that arise from da...  \n",
       "209  Baidu Deep Voice explained: Part 1 — the Infer...  \n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, numpy as np\n",
    "\n",
    "def parse_url(url=\"http://www.datatau.com\", data=False):\n",
    "    \n",
    "    response  =  requests.get(url)\n",
    "    links     =  Selector(text=response.text).xpath(\"//td[@class='title']/a/@href\").extract()\n",
    "    titles    =  Selector(text=response.text).xpath(\"//td[@class='title']/a/text()\").extract()\n",
    "    points    =  Selector(text=response.text).xpath(\"//td[@class='subtext']/span/text()\").extract()\n",
    "    domains   =  Selector(text=response.text).xpath(\"//td[@class='title']/span/text()\").extract()\n",
    "    authors   =  Selector(text=response.text).xpath(\"//td[@class='subtext']/a[contains(@href, 'user')]/text()\").extract()\n",
    "    comments  =  Selector(text=response.text).xpath(\"//td[@class='subtext']/a[contains(@href, 'item')]/text()\").extract()\n",
    "\n",
    "    expected_length = 30\n",
    "    \n",
    "    # [np.nan]*(expected_length - len(points)) to the end of the lists, will fill in missing\n",
    "    # values at the end that sometimes don't exist at the ends of the results\n",
    "    scraped = dict(\n",
    "        titles   =  titles[:30], \n",
    "        links    =  links[:30], # :30 because of that damn \"more\" link\n",
    "        points   =  points + [np.nan]*(expected_length - len(points)),\n",
    "        domains  =  domains + [np.nan]*(expected_length - len(domains)),\n",
    "        authors  =  authors + [np.nan]*(expected_length - len(authors)),\n",
    "        comments =  comments + [np.nan]*(expected_length - len(comments))\n",
    "    )\n",
    "    \n",
    "    df = pd.DataFrame(scraped)\n",
    "    \n",
    "    if type(data) != bool:\n",
    "        data = df.append(data)\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    # If there's data append it, if not, it's the first iteration, no need.\n",
    "    # Find more link\n",
    "    more_anchor  =  Selector(text=response.text).xpath(\"//a[text() = 'More']/@href\").extract()\n",
    "    \n",
    "    if len(more_anchor) > 0:\n",
    "        more_url  =  \"http://www.datatau.com%s\" % more_anchor[0]\n",
    "        print \"Fetching %s...\" % more_url\n",
    "        return parse_url(more_url, data=data)\n",
    "    else:\n",
    "        return data.reset_index()\n",
    "       \n",
    "        \n",
    "df = parse_url(\"http://www.datatau.com\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Practicing Web Scraping with XPath\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "*After this lesson, you will be able to:*\n",
    "- Practice scraping basics\n",
    "- Review HTML and XPath basics\n",
    "- Practice scraping a website for various data and put this into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Review of HTML and web scraping](#review1)\n",
    "- [Review of XPath](#review2)\n",
    "- [Basic XPath expressions](#basic-xpath)\n",
    "    - [Absolute references](#absolute-references)\n",
    "    - [Relative references](#relative-references)\n",
    "    - [Selecting attributes](#attributes)\n",
    "- [Guided practice: Where's Waldo - \"XPath Edition\"](#practice1)\n",
    "- [1 vs. N selections](#1vsn)\n",
    "    - [Selecting the first element in a series of elements](#first-elem)\n",
    "    - [Selecting the last element in a series of elements](#last-elem)\n",
    "    - [Selecting all elements matching a selection](#all-elem-match)\n",
    "    - [Selecting elements matching an attribute](#elem-match-attr)\n",
    "- [Guided practice: selecting elements](#practice2)\n",
    "- [A quick note: the requests module](#requests)\n",
    "- [Guided practice: scrape Data Tau headlines](#practice3)\n",
    "- [Independent practice](#independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review1'></a>\n",
    "## Review of HTML and web scraping\n",
    "\n",
    "---\n",
    "\n",
    "Web scraping is a technique of extracting information from websites. It is the download and transformation of unstructured data on the web into structured data that can be stored and analyzed.\n",
    "\n",
    "There are a variety of ways to \"scrape\" what we want from the web:\n",
    "- 3rd Party Services (import.io)\n",
    "- Write our own Python apps that pull HTML documents and parse them\n",
    "  - Mechanize\n",
    "  - Scrapy\n",
    "  - Requests\n",
    "  - libxml / XPath\n",
    "  - Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Check:** What is hardest to understand about scraping?\n",
    "\n",
    "_ie: If you were asked to scrape craigslist property listings and put them in a DataFrame(), what would hold you up?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: HTML\n",
    "\n",
    "In the HTML DOM (Document Object Model), everything is a node:\n",
    " * The document itself is a document node.\n",
    " * All HTML elements are element nodes.\n",
    " * All HTML attributes are attribute nodes.\n",
    " * Text inside HTML elements are text nodes.\n",
    " * Comments are comment nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: elements\n",
    "Elements begin and end with **open and close \"tags\"**, which are defined by namespaced, encapsulated strings. \n",
    "\n",
    "```html\n",
    "<title>I am a title.</title>\n",
    "<p>I am a paragraph.</p>\n",
    "<strong>I am bold.</strong>\n",
    "```\n",
    "\n",
    "_note: the tags **title, p, and strong** are represented here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: element parent / child relationships\n",
    "\n",
    "<img src=\"http://www.htmlgoodies.com/img/2007/06/flowChart2.gif\" width=\"250\">\n",
    "\n",
    "**Elements begin and end in the same namespace like so:**  `<p></p>`\n",
    "\n",
    "**Elements can have parents and children:**\n",
    "\n",
    "```html\n",
    "<body>\n",
    "    <div>I am inside the parent element\n",
    "        <div>I am inside a child element</div>\n",
    "        <div>I am inside another child element</div>\n",
    "        <div>I am inside yet another child element</div>\n",
    "    </div>\n",
    "</body>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: element attributes\n",
    "\n",
    "Elements can also have attributes!  Attributes are defined inside **element tags** and can contain data that may be useful to scrape.\n",
    "\n",
    "```html\n",
    "<a href=\"http://lmgtfy.com/?q=html+element+attributes\" title=\"A title\" id=\"web-link\" name=\"hal\">A Simple Link</a>\n",
    "```\n",
    "\n",
    "The **element attributes** of this `<a>` tag element are:\n",
    "- id\n",
    "- href\n",
    "- title\n",
    "- name\n",
    "\n",
    "This `<a>` tag example will render in your browser like this:\n",
    "> <a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">A Simple Link</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** Can you identify an attribute, an element, a text item, and a child element?\n",
    "\n",
    "```HTML\n",
    "<html>\n",
    "   <title id=\"main-title\">All this scraping is making me itch!</title>\n",
    "   <body>\n",
    "       <h1>Welcome to my Homepage</h1>\n",
    "       <p id=\"welcome-paragraph\" class=\"strong-paragraph\">\n",
    "           <span>Hello friends, let me tell you about this cool hair product..</span>\n",
    "           <ul>\n",
    "              <li>It's cool</li>\n",
    "              <li>It's fresh</li>\n",
    "              <li>It can tell the future</li>\n",
    "              <li>Always be closing</li>\n",
    "           </ul>\n",
    "       </p>\n",
    "   </body>\n",
    "```\n",
    "\n",
    "**Bonus: What's missing?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review2'></a>\n",
    "## Review of XPath\n",
    "\n",
    "---\n",
    "\n",
    "XPath uses path expressions to select nodes or node-sets in an HTML/XML document. These path expressions look very much like the expressions you see when you work with a traditional computer file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XPath features\n",
    "\n",
    "XPath includes over 100 built-in functions to help us select and manipulate HTML (or XML) documents. XPath has functions for:\n",
    "\n",
    "- string values\n",
    "- numeric values\n",
    "- date and time comparison\n",
    "- sequence manipulation\n",
    "- Boolean values\n",
    "- and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basic-xpath'></a>\n",
    "## Basic XPath expressions\n",
    "\n",
    "---\n",
    "\n",
    "XPath comes with a wide array of features but the basics of selecting data are the most common problems that XPath can help you solve.\n",
    "\n",
    "The most common task you'll use **XPath** for is selecting data from HTML documents.  There are two ways you can **select elements** within HTML using **XPath**:\n",
    "\n",
    "- Absolute reference\n",
    "- Relative reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='absolute'></a>\n",
    "### Absolute references\n",
    "\n",
    "> _For our XPath demonstration, we will use Scrapy, which is using libxml under the hood.  Libxml provides the basic functionality for XPath expressions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'good']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install scrapy\n",
    "# pip install --upgrade zope2\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <span id=\"only-span\">good</span>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "# The same thing but \"absolute\" reference\n",
    "Selector(text=HTML).xpath('/html/body/span/text()').extract()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='relative-references'></a>\n",
    "### Relative references\n",
    "\n",
    "Relative references in XPath match the \"ends\" of structures.  Since there is only a single \"span\" element, `//span/text()` matches **one element**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'good']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='attributes'></a>\n",
    "### Selecting attributes\n",
    "\n",
    "Attributes **within a tag**, such as `id=\"only-span\"` within our span attribute.  We can get the attribute by using `@` symbol **after** the **element reference**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'only-span']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span/@id').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice1'></a>\n",
    "## Guided practice: Where's Waldo - \"XPath Edition\"\n",
    "\n",
    "---\n",
    "\n",
    "**In this example, we will find Waldo together.  Find Waldo as an:**\n",
    "\n",
    "- Element\n",
    "- Attribute\n",
    "- Text element\n",
    "\n",
    "The practice HTML string is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        \n",
    "        <ul id=\"waldo\">\n",
    "            <li class=\"waldo\">\n",
    "                <span> yo Im not here</span>\n",
    "            </li>\n",
    "            <li class=\"waldo\">Height:  ???</li>\n",
    "            <li class=\"waldo\">Weight:  ???</li>\n",
    "            <li class=\"waldo\">Last Location:  ???</li>\n",
    "            <li class=\"nerds\">\n",
    "                <div class=\"alpha\">Bill gates</div>\n",
    "                <div class=\"alpha\">Zuckerberg</div>\n",
    "                <div class=\"beta\">Theil</div>\n",
    "                <div class=\"animal\">parker</div>\n",
    "            </li>\n",
    "        </ul>\n",
    "        \n",
    "        <ul id=\"tim\">\n",
    "            <li class=\"tdawg\">\n",
    "                <span>yo im here</span>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <li>stuff</li>\n",
    "        <li>stuff2</li>\n",
    "        \n",
    "        <div id=\"cooldiv\">\n",
    "            <span class=\"dsi-rocks\">\n",
    "               YO!\n",
    "            </span>\n",
    "        </div>\n",
    "        \n",
    "        \n",
    "        <waldo>Waldo</waldo>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'waldo',\n",
       " u'waldo',\n",
       " u'waldo',\n",
       " u'waldo',\n",
       " u'nerds',\n",
       " u'alpha',\n",
       " u'alpha',\n",
       " u'beta',\n",
       " u'animal',\n",
       " u'tdawg',\n",
       " u'dsi-rocks']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//@class').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Waldo']\n",
      "[u'\\n                ', u'\\n            ', u'Height:  ???', u'Weight:  ???', u'Last Location:  ???', u'\\n                ', u'\\n                ', u'\\n                ', u'\\n                ', u'\\n            ', u'\\n                ', u'\\n            ']\n",
      "[u'<li class=\"waldo\">\\n                <span> yo Im not here</span>\\n            </li>', u'<li class=\"waldo\">Height:  ???</li>', u'<li class=\"waldo\">Weight:  ???</li>', u'<li class=\"waldo\">Last Location:  ???</li>', u'<li class=\"nerds\">\\n                <div class=\"alpha\">Bill gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">parker</div>\\n            </li>', u'<li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>', u'<li>stuff</li>', u'<li>stuff2</li>']\n",
      "[u'waldo', u'waldo', u'waldo', u'waldo', u'nerds', u'alpha', u'alpha', u'beta', u'animal', u'tdawg', u'dsi-rocks']\n",
      "[u'waldo', u'tim']\n"
     ]
    }
   ],
   "source": [
    "# Find absolute element\n",
    "print Selector(text=HTML).xpath('/html/body/waldo/text()').extract()\n",
    "print Selector(text=HTML).xpath('/html/body/ul/li/text()').extract()\n",
    "\n",
    "# Find relative element\n",
    "print Selector(text=HTML).xpath('//li').extract()\n",
    "\n",
    "# Find element attribute\n",
    "print Selector(text=HTML).xpath('////@class').extract()\n",
    "print Selector(text=HTML).xpath('//ul/@id').extract()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1vsn'></a>\n",
    "## 1 vs N selections\n",
    "\n",
    "---\n",
    "\n",
    "When selecting elements via relative reference, it's possible that you will select multiple items.  It's still possible to select single items, if you're specfic enough.\n",
    "\n",
    "**Singular Reference**\n",
    "- **Index** starts at **1**\n",
    "- Selections by offset\n",
    "- Selections by \"first\" or \"last\"\n",
    "- Selections by **unique attribute value**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'5,233.42']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "    \n",
    "        <!-- Search Results -->\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=751hUX_q0Do\" title=\"Rappin with Gas\">Rapping with gas</a>\n",
    "           <span class=\"link-details\">This is a great video about gas.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=97byWqi-zsI\" title=\"Casio Rapmap\">The Rapmaster</a>\n",
    "           <span class=\"link-details\">My first synth ever.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=TSwqnR327fk\" title=\"Cinco Products\">Cinco Midi Organizer</a>\n",
    "           <span class=\"link-details\">Midi files at the speed of light.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=8TCxE0bWQeQ\" title=\"Baddest Gates\">BBG Baddest Moments</a>\n",
    "           <span class=\"link-details\">It's tough to be a gangster.</span>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Page stats -->\n",
    "        <div class=\"page-stats-container\">\n",
    "            <li class=\"item\" id=\"pageviews\">1,333,443</li>\n",
    "            <li class=\"item\" id=\"somethingelse\">bla</li>\n",
    "            <li class=\"item\" id=\"last-viewed\">01-22-2016</li>\n",
    "            <li class=\"item\" id=\"views-per-hour\">1,532</li>\n",
    "            <li class=\"item\" id=\"kiefer-views-per-hour\">5,233.42</li>\n",
    "        </div>\n",
    "        \n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "span = Selector(text=HTML).xpath('/html/body/div/li[@id=\"kiefer-views-per-hour\"]/text()').extract()\n",
    "span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='first-elem'></a>\n",
    "### Selecting the first element in a series of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<span class=\"link-details\">This is a great video about gas.</span>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = Selector(text=HTML).xpath('//span').extract()\n",
    "spans[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='last-elem'></a>\n",
    "### Selecting the last element in a series of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<span class=\"link-details\">It\\'s tough to be a gangster.</span>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = Selector(text=HTML).xpath('//span').extract()\n",
    "spans[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='all-elem-match'></a>\n",
    "### Selecting all elements matching a selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'<span class=\"link-details\">This is a great video about gas.</span>',\n",
       " u'<span class=\"link-details\">My first synth ever.</span>',\n",
       " u'<span class=\"link-details\">Midi files at the speed of light.</span>',\n",
       " u'<span class=\"link-details\">It\\'s tough to be a gangster.</span>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='elem-match-attr'></a>\n",
    "### Selecting elements matching an _attribute_\n",
    "\n",
    "This will be one of the most common ways you will select items.  HTML DOM elements will be more differentiated based on their \"class\" and \"id\" variables.  Mainly, these types of attributes are used by web developers to refer to specfic elements or a broad set of elements to apply visual characteristics using CSS.\n",
    "\n",
    "```HTML \n",
    "//element[@attribute=\"value\"]\n",
    "```\n",
    "\n",
    "**Generally**\n",
    "\n",
    "- \"class\" attributes within elements usually refer to multiple items\n",
    "- \"id\" attributes are supposed to be unique, but not always\n",
    "\n",
    "_CSS stands for cascading style sheets.  These are used to abstract the definition of visual elements on a micro and macro scale for the web.  They are also our best friend as data miners.  They give us strong hints and cues as to how a web document is structured._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice2'></a>\n",
    "## Guided practice: selecting elements\n",
    "\n",
    "---\n",
    "\n",
    "1. **How can we get a series of only text items for the page statistics section of our page?**\n",
    "2. **We want to know only how many times Kiefer views my Youtube videos page per hour?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='//li/text()' data=u'1,333,443'>,\n",
       " <Selector xpath='//li/text()' data=u'bla'>,\n",
       " <Selector xpath='//li/text()' data=u'01-22-2016'>,\n",
       " <Selector xpath='//li/text()' data=u'1,532'>,\n",
       " <Selector xpath='//li/text()' data=u'5,233.42'>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all text elements for the page statistics section\n",
    "Selector(text=HTML).xpath('//li/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'5,233.42']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the text for \"Kiefer's\" number of views per hour\n",
    "# Selector(text=HTML).xpath('//div[@class=\"page-stats-container\"]/li[4]/text()').extract()\n",
    "\n",
    "# Get only the text for \"Kiefer's\" number of views per hour\n",
    "Selector(text=HTML).xpath('//li[@id=\"kiefer-views-per-hour\"]/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "## A quick note:  the `requests` module\n",
    "\n",
    "---\n",
    "\n",
    "The requests module is the gateway to interacting with the web using Python.  We can:\n",
    "\n",
    " - Fetch web documents as strings\n",
    " - Decode JSON\n",
    " - Basic data munging with Web Documents\n",
    " - Download static files that are not text\n",
    "  - Images\n",
    "  - Videos\n",
    "  - Binary data\n",
    "\n",
    "\n",
    "Take some time and read up on Requests:\n",
    "\n",
    "http://docs.python-requests.org/en/master/user/quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice3'></a>\n",
    "## Guided practice: scrape Data Tau headlines\n",
    "\n",
    "DataTau is a great site for data science news. Let's take their headlines using Python **`requests`**, and practice selecting various elements.\n",
    "\n",
    "Using <a href=\"https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=en\">XPath helper Chrome plugin</a> _(cmd-shift-x)_ and the Chrome \"inspect\" feature, let's explore the structure of the page.\n",
    "\n",
    "_Here's a <a href=\"https://www.youtube.com/watch?v=i2Li1vnv09U\">concise video</a> that demonstrates the basic inspect feature within Chrome._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<html><head><link rel=\"stylesheet\" type=\"text/css\" href=\"news.css\">\\n<link rel=\"shortcut icon\" href=\"http://www.iconj.com/ico/d/x/dxo02ap56v.ico\">\\n<scr'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please only run this frame once to avoid hitting the site too hard all at once\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"http://www.datatau.com\")\n",
    "HTML = response.text  \n",
    "HTML[0:150]           # view the first 500 characters of the HTML index document for DataTau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Only The Headlines\n",
    "\n",
    "We will use the XPath helper tool to inspect the markup that comprises the **title** to find any pattern.  Since there are more than one **titles**, we expect to find a series of elements representing the **title** data that we are interested in.\n",
    "\n",
    "![](https://snag.gy/m4K3UE.jpg)\n",
    "\n",
    "In this example, we are referencing the the **1st center**, **3rd table row (`tr[3]`)**, within the 2nd **td having a class of \"title\" (`td[@class=\"title\"][2]`)**, and the anchor tag within a **(`a/text()`)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Intro to a ML algorithm that tends to fly below the radar: Self-Organizing Maps',\n",
       " u'Interview questions for data scientists',\n",
       " u'A list of must read books for Data Science',\n",
       " u'How Soft Clustering for HDBSCAN Works',\n",
       " u\"What's wrong with my time series? Error measurement and validation for modeling\",\n",
       " u'How to choose a project to practice data science',\n",
       " u'The Reasonable Effectiveness of the Multiplicative Weights Update Algorithm',\n",
       " u'How to Start an R Project',\n",
       " u'Time Person of the Year\\u200a\\u2014\\u200aA snapshot of history with data',\n",
       " u'Random-Walk Bayesian Deep Networks in PyMC3']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titles = Selector(text=HTML).xpath('//td[@class=\"title\"]/a/text()').extract()\n",
    "titles[0:10] # the first 5 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we get the urls from the titles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/x?fnid=Klezik46MX',\n",
       " u'https://medium.com/athelas/paper-1-baidus-deep-voice-675a323705df#.jo8jmxx0o',\n",
       " u'https://www.mapd.com/blog/2017/03/03/the-forest-and-the-trees/',\n",
       " u'https://arxiv.org/abs/1702.08835',\n",
       " u'https://github.com/jwkvam/bowtie',\n",
       " u'https://www.neuraldesigner.com/blog/5_algorithms_to_train_a_neural_network',\n",
       " u'http://tech.marksblogg.com/tensorflow-vizdoom-bots.html',\n",
       " u'https://research.fb.com/prophet-forecasting-at-scale/',\n",
       " u'https://data36.com/command-line-data-science-introduction-to-bash/',\n",
       " u'https://blog.godatadriven.com/how-to-start-a-data-science-project-in-python',\n",
       " u'https://danidelvalle.me/2017/03/09/engaging-your-audience-with-email-attractive-contents-mjml-jinja2-owncloud-airflow/',\n",
       " u'https://blog.wikimedia.org/2017/02/02/hiring-data-scientist/',\n",
       " u'https://developers.googleblog.com/2017/03/xla-tensorflow-compiled.html',\n",
       " u'https://medium.com/@kacawi/ipython-or-jupyter-10a9fb82682b',\n",
       " u'https://arxiv.org/abs/1702.05243',\n",
       " u'https://blog.dominodatalab.com/fitting-gaussian-process-models-python/',\n",
       " u'https://techcrunch.com/2017/03/07/google-is-acquiring-data-science-community-kaggle/',\n",
       " u'https://blog.alookanalytics.com/2017/03/08/8-simple-ways-how-to-boost-your-coding-skills-not-just-in-r/',\n",
       " u'https://github.com/yandexdataschool/Practical_RL',\n",
       " u'http://algorithms-tour.stitchfix.com/',\n",
       " u'http://cooldatasets.com/',\n",
       " u'http://twiecki.github.io/blog/2017/03/14/random-walk-deep-net/',\n",
       " u'https://medium.com/learning-machine-learning/time-person-of-the-year-a-snapshot-of-history-with-data-cab63926e1a2#.abp9sh1wi',\n",
       " u'https://blog.datazar.com/how-to-start-an-r-project-8501819634d4#.yuofoes20',\n",
       " u'https://jeremykun.com/2017/02/27/the-reasonable-effectiveness-of-the-multiplicative-weights-update-algorithm/',\n",
       " u'http://sharpsightlabs.com/blog/choose-project-practice-data-science/',\n",
       " u'https://blog.insightdatascience.com/whats-wrong-with-my-time-series-model-validation-without-a-hold-out-set-94151d38cf5b#.jwy7xgvxc',\n",
       " u'http://hdbscan.readthedocs.io/en/latest/soft_clustering_explanation.html',\n",
       " u'http://blog.paralleldots.com/data-scientist/list-must-read-books-data-science/',\n",
       " u'https://shapescience.xyz/blog/interview-questions-for-data-scientists/',\n",
       " u'http://blog.yhat.com/posts/self-organizing-maps-1.html']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = Selector(text=HTML).xpath('//td[@class=\"title\"]/a/@href').extract()\n",
    "urls[::-1]\n",
    "#<a href=\"http://tech.marksblogg.com/faster-queries-google-cloud-dataproc.html\">33x Faster Queries on Google Cloud's Dataproc using Facebook's Presto</a>\n",
    "# titles[0:5] # the first 5 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we get the site domain, after the title within the parentheses (ie: stitchfix.com)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domains = Selector(text=HTML).xpath(\"//span[@class='comhead']/text()\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u' (yhat.com) ',\n",
       " u' (shapescience.xyz) ',\n",
       " u' (paralleldots.com) ',\n",
       " u' (readthedocs.io) ',\n",
       " u' (insightdatascience.com) ']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about the points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'2 points', u'3 points', u'4 points', u'3 points', u'5 points']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = Selector(text=HTML).xpath('//td[@class=\"subtext\"]/span/text()').extract()\n",
    "points[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about the \"more Link?\"\n",
    "\n",
    "> *Hint:  You can use `element[text()='exact text']` to find text element matching specific text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/x?fnid=Klezik46MX']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_link = Selector(text=HTML).xpath('//a[text()=\"More\"]/@href').extract()\n",
    "next_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='independent'></a>\n",
    "## Independent practice\n",
    "\n",
    "---\n",
    "\n",
    "**For the next 30 minutes try to grab the following from Data Tau:**\n",
    "\n",
    "- Story titles\n",
    "- Story URL (href)\n",
    "- Domain\n",
    "- Points\n",
    "\n",
    "**Stretch goals:**\n",
    "- Author\n",
    "- Comment count\n",
    "\n",
    "**Put your results into a DataFrame.**\n",
    "\n",
    "- Do basic analysis of domains and point distributions\n",
    "\n",
    "**BONUS:**\n",
    "\n",
    "Automatically find the next \"more link\" and mine the next page(s) until none exist.  Logically, you can each page with this pseudo code:\n",
    "\n",
    "1. Does the next link exist (a tag with text == \"More\")\n",
    "- Fetch URL, prepended with domain (datatau.com/(extracted link here))\n",
    "- Parse the page with `Selector(text=HTML).xpath('').extract()` to find the elements\n",
    "- Add to dataframe\n",
    "\n",
    "> _Note:  You might want to set a limit something like 2-3 total requests per attempt to avoid unecessary transfer._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching http://www.datatau.com/x?fnid=nFwY3ptqum...\n",
      "Fetching http://www.datatau.com/x?fnid=i5qw13CEWd...\n",
      "Fetching http://www.datatau.com/x?fnid=HJ8nnP9wU2...\n",
      "Fetching http://www.datatau.com/x?fnid=FhZvn3Louv...\n",
      "Fetching http://www.datatau.com/x?fnid=dYA8mknuan...\n",
      "Fetching http://www.datatau.com/x?fnid=vUOqE1IZKu...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>authors</th>\n",
       "      <th>comments</th>\n",
       "      <th>domains</th>\n",
       "      <th>links</th>\n",
       "      <th>points</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>elyase</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(explosion.ai)</td>\n",
       "      <td>https://explosion.ai/blog/quora-deep-text-pair...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Deep text-pair classification with Quora's 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>kkwteh</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(opendoor.com)</td>\n",
       "      <td>https://labs.opendoor.com/2017/02/17/two-cultu...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>The Two Cultures of Machine Learning Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>elisebreda</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(yhat.com)</td>\n",
       "      <td>http://blog.yhat.com/posts/R-for-excel-users.html</td>\n",
       "      <td>5 points</td>\n",
       "      <td>R for Excel Users</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>data36</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/data36/wannabe-data-scienti...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>Wannabe Data Scientist! Here are 8 free online...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>kkwteh</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(opendoor.com)</td>\n",
       "      <td>https://labs.opendoor.com/2017/02/16/building-...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>How to keep your data scientists and engineers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>miroli</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(urbanspatialanalysis.com)</td>\n",
       "      <td>http://urbanspatialanalysis.com/portfolio/pred...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Predicting gentrification using longitudinal c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>data36</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(data36.com)</td>\n",
       "      <td>http://data36.com/data-resistance-evangelize-d...</td>\n",
       "      <td>7 points</td>\n",
       "      <td>Data-resistance – How to evangelize the data d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>coglog</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(willwolf.io)</td>\n",
       "      <td>item?id=16765</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Engineered features for dataset boosting for N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>cavaunpeu</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(deeplearningweekly.com)</td>\n",
       "      <td>http://willwolf.io/en/2017/02/03/bayesian-esti...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>RescueTime Estimation via the \"Poor Man's Diri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>buss_jan</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(webhose.io)</td>\n",
       "      <td>http://www.deeplearningweekly.com/blog/demysti...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Demystifying Word2Vec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>rangeva</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(zinkevich.org)</td>\n",
       "      <td>http://blog.webhose.io/2017/02/09/how-to-use-r...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>How to use Webhose.io rated reviews for sentim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>jast</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(googleblog.com)</td>\n",
       "      <td>http://martin.zinkevich.org/rules_of_ml/rules_...</td>\n",
       "      <td>30 points</td>\n",
       "      <td>\\tBest Practices for ML Engineering from Googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>antognini</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(slideshare.net)</td>\n",
       "      <td>http://www.scribd.com/vacuum?url=http://martin...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>scribd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Brainvire</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(datumbox.com)</td>\n",
       "      <td>https://research.googleblog.com/2017/02/using-...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Using Machine Learning to predict parking diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>datumbox</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(insightdatascience.com)</td>\n",
       "      <td>http://www.slideshare.net/brainvireinfo/nodejs...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Advantage of Node.js Development For Business ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>mwakanosya</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(ethanrosenthal.com)</td>\n",
       "      <td>http://blog.datumbox.com/getting-the-gpu-usage...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Getting the GPU usage of NVIDIA cards with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>thang</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(sharpsightlabs.com)</td>\n",
       "      <td>https://blog.insightdatascience.com/anonymizat...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Anonymizing documents with Word Vectors and O(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>SharpSightLabs</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(marksblogg.com)</td>\n",
       "      <td>http://blog.ethanrosenthal.com/2017/02/05/rec-...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Rec-a-Sketch: a Flask App for Interactive Sket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>mapd</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(christopherroach.com)</td>\n",
       "      <td>http://sharpsightlabs.com/blog/map-geospatial-...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Beautiful data: mapping USA rivers with ggplot2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>croach</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(alookanalytics.com)</td>\n",
       "      <td>http://tech.marksblogg.com/benchmarks.html</td>\n",
       "      <td>15 points</td>\n",
       "      <td>DB benchmark shootout on 1.2B row NYC taxi dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>adam_alook</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(aylien.com)</td>\n",
       "      <td>http://christopherroach.com/articles/statistic...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Statistics for Hackers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>mikewally</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://blog.alookanalytics.com/2017/01/30/pyt...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Running Python on the Cloud - essentials for D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>kawica</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>http://blog.aylien.com/sentiment-analysis-of-2...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Sentiment Analysis of 2.2 million tweets from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>flovv</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(willwolf.io)</td>\n",
       "      <td>https://medium.com/@kacawi/python-excel-tutori...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Python and Excel: The Definitive Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>cavaunpeu</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(sharpsightlabs.com)</td>\n",
       "      <td>http://flovv.github.io/From_descritpive_to_pre...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>From Descriptive to Prescriptive Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>SharpSightLabs</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(mapd.com)</td>\n",
       "      <td>http://willwolf.io/en/2017/02/07/bayesian-infe...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Bayesian Inference via Simulated Annealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>tmostak</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(alookanalytics.com)</td>\n",
       "      <td>http://sharpsightlabs.com/blog/human-capital-map/</td>\n",
       "      <td>5 points</td>\n",
       "      <td>One thing critical for success in the age of A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>adam_alook</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(yhat.com)</td>\n",
       "      <td>https://www.mapd.com/blog/2017/02/03/mapd-2-0-...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>How we made GPU-powered MapD even faster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>elisebreda</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(mike.place)</td>\n",
       "      <td>https://blog.alookanalytics.com/2017/02/05/how...</td>\n",
       "      <td>7 points</td>\n",
       "      <td>How to plot your own bike/jogging route using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>mikepqr</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://blog.yhat.com/posts/deep-learning-chess...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Deep Learning for Chess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>marklit</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(marksblogg.com)</td>\n",
       "      <td>http://tech.marksblogg.com/billion-nyc-taxi-ri...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>1.1 Billion Taxi Rides with MapD 3.0 &amp; 2 GPU-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1</td>\n",
       "      <td>kokorcsin</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(data36.com)</td>\n",
       "      <td>https://data36.com/learn-data-analytics-bash-s...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>7 articles to learn basics of Command Line/Bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2</td>\n",
       "      <td>deeplearningt</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(deeplearningtrack.com)</td>\n",
       "      <td>https://www.deeplearningtrack.com/single-post/...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>Deep Learning intuition for a business user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>3</td>\n",
       "      <td>Soapbox</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(sp-bx.com)</td>\n",
       "      <td>https://www.sp-bx.com/getting-grips-blockchain/</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Getting to grips with Blockchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>4</td>\n",
       "      <td>lmcinnes</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>http://lmcinnes.github.io/subreddit_mapping/</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Mapping and Analysing SubReddits Using Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>5</td>\n",
       "      <td>Soapbox</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(sp-bx.com)</td>\n",
       "      <td>https://www.sp-bx.com/5-ways-make-business-sma...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>5 Ways To Make Your Business Smarter Using Aug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>6</td>\n",
       "      <td>axelr</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>http://arogozhnikov.github.io/2017/04/20/machi...</td>\n",
       "      <td>11 points</td>\n",
       "      <td>Machine Learning in Science and Industry [slides]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>7</td>\n",
       "      <td>cavaunpeu</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(willwolf.io)</td>\n",
       "      <td>http://willwolf.io/2017/04/19/deriving-the-sof...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Deriving the Softmax from First Principles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>8</td>\n",
       "      <td>Weenkus</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(datawhatnow.com)</td>\n",
       "      <td>http://datawhatnow.com/feature-importance/</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Feature importance and why it's important</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>9</td>\n",
       "      <td>deeplearningt</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(deeplearningtrack.com)</td>\n",
       "      <td>https://www.deeplearningtrack.com/single-post/...</td>\n",
       "      <td>15 points</td>\n",
       "      <td>Learn under the hood of Gradient Descent algor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>10</td>\n",
       "      <td>blester</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(abigailsee.com)</td>\n",
       "      <td>http://www.abigailsee.com/2017/04/16/taming-rn...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Abstractive Summary with Pointer-Generator Net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>11</td>\n",
       "      <td>jmsmistral</td>\n",
       "      <td>3 comments</td>\n",
       "      <td>(jonathansacramento.com)</td>\n",
       "      <td>http://jonathansacramento.com/posts/20170416_c...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Predicting Churn without Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>12</td>\n",
       "      <td>gargisharma</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(paralleldots.com)</td>\n",
       "      <td>http://blog.paralleldots.com/data-scientist/7-...</td>\n",
       "      <td>14 points</td>\n",
       "      <td>7 types of job profiles that make you a Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>13</td>\n",
       "      <td>alexandraj777</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(sigopt.com)</td>\n",
       "      <td>http://blog.sigopt.com/post/159685042073/sigop...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Expected Improvement vs. Knowledge Gradient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>14</td>\n",
       "      <td>enmanuel</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(blogspot.com.ar)</td>\n",
       "      <td>http://python-apuntes.blogspot.com.ar/2017/04/...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Python script for create dummies (using \"featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>15</td>\n",
       "      <td>Hx</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(intel.com)</td>\n",
       "      <td>https://software.intel.com/en-us/blogs/2017/04...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Intel and Facebook* Collaborate to Boost Caffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>16</td>\n",
       "      <td>jahan</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(aioptify.com)</td>\n",
       "      <td>http://www.aioptify.com/top-prediction-books.php</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Top Books on Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>17</td>\n",
       "      <td>okcdata</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(okcupid.com)</td>\n",
       "      <td>https://tech.okcupid.com/the-pitfalls-of-a-b-t...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>The pitfalls of A/B testing in social networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>18</td>\n",
       "      <td>gargisharma</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(paralleldots.com)</td>\n",
       "      <td>http://blog.paralleldots.com/technology/deep-l...</td>\n",
       "      <td>10 points</td>\n",
       "      <td>Some Lesser-Known Deep Learning Libraries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>19</td>\n",
       "      <td>Argentum01</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(theintercept.com)</td>\n",
       "      <td>https://trial-and-terror.theintercept.com/</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Most people prosecuted for terrorism since 9/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>20</td>\n",
       "      <td>gargisharma</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(paralleldots.com)</td>\n",
       "      <td>http://blog.paralleldots.com/technology/machin...</td>\n",
       "      <td>17 points</td>\n",
       "      <td>Some Lesser Known Machine Learning Libraries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>21</td>\n",
       "      <td>mapd</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(mapd.com)</td>\n",
       "      <td>https://www.mapd.com/blog/2017/04/14/quick-ins...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Quick visual insight with cross-filtering in M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>22</td>\n",
       "      <td>displayr1</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(displayr.com)</td>\n",
       "      <td>https://www.displayr.com/blog/</td>\n",
       "      <td>8 points</td>\n",
       "      <td>Data science tool in early beta (so it's free)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>23</td>\n",
       "      <td>sergios</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(neuraldesigner.com)</td>\n",
       "      <td>https://www.neuraldesigner.com/blog/market-bas...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Market Basket Analysis using R and Neural Desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>24</td>\n",
       "      <td>sqadri</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(jupyter.org)</td>\n",
       "      <td>http://blog.jupyter.org/2017/04/04/jupyter-not...</td>\n",
       "      <td>20 points</td>\n",
       "      <td>Jupyter Notebook 5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>25</td>\n",
       "      <td>gargisharma</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(paralleldots.com)</td>\n",
       "      <td>http://blog.paralleldots.com/technology/machin...</td>\n",
       "      <td>20 points</td>\n",
       "      <td>List of Free Must-Read Books for Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>26</td>\n",
       "      <td>DataScienceInc</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(datascience.com)</td>\n",
       "      <td>https://www.datascience.com/trends/machine-lea...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>Visualize and share trends in GitHub activity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>27</td>\n",
       "      <td>deeplearningt</td>\n",
       "      <td>3 comments</td>\n",
       "      <td>(deeplearningtrack.com)</td>\n",
       "      <td>https://www.deeplearningtrack.com/</td>\n",
       "      <td>15 points</td>\n",
       "      <td>An innovative approach to learn data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>28</td>\n",
       "      <td>adam_alook</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(alookanalytics.com)</td>\n",
       "      <td>https://blog.alookanalytics.com/2017/04/11/int...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>Intuition vs Unsupervised Learning – Agglomera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>29</td>\n",
       "      <td>ata_aman</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(datazar.com)</td>\n",
       "      <td>https://blog.datazar.com/announcing-datazar-v2...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Announcing Datazar v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index         authors    comments                       domains  \\\n",
       "0        0          elyase     discuss               (explosion.ai)    \n",
       "1        1          kkwteh     discuss               (opendoor.com)    \n",
       "2        2      elisebreda     discuss                   (yhat.com)    \n",
       "3        3          data36   1 comment                 (medium.com)    \n",
       "4        4          kkwteh     discuss               (opendoor.com)    \n",
       "5        5          miroli     discuss   (urbanspatialanalysis.com)    \n",
       "6        6          data36     discuss                 (data36.com)    \n",
       "7        7          coglog  2 comments                (willwolf.io)    \n",
       "8        8       cavaunpeu     discuss     (deeplearningweekly.com)    \n",
       "9        9        buss_jan     discuss                 (webhose.io)    \n",
       "10      10         rangeva     discuss              (zinkevich.org)    \n",
       "11      11            jast     discuss             (googleblog.com)    \n",
       "12      12       antognini     discuss             (slideshare.net)    \n",
       "13      13       Brainvire     discuss               (datumbox.com)    \n",
       "14      14        datumbox     discuss     (insightdatascience.com)    \n",
       "15      15      mwakanosya     discuss         (ethanrosenthal.com)    \n",
       "16      16           thang     discuss         (sharpsightlabs.com)    \n",
       "17      17  SharpSightLabs     discuss             (marksblogg.com)    \n",
       "18      18            mapd     discuss       (christopherroach.com)    \n",
       "19      19          croach   1 comment         (alookanalytics.com)    \n",
       "20      20      adam_alook     discuss                 (aylien.com)    \n",
       "21      21       mikewally     discuss                 (medium.com)    \n",
       "22      22          kawica     discuss                  (github.io)    \n",
       "23      23           flovv     discuss                (willwolf.io)    \n",
       "24      24       cavaunpeu     discuss         (sharpsightlabs.com)    \n",
       "25      25  SharpSightLabs     discuss                   (mapd.com)    \n",
       "26      26         tmostak     discuss         (alookanalytics.com)    \n",
       "27      27      adam_alook     discuss                   (yhat.com)    \n",
       "28      28      elisebreda   1 comment                 (mike.place)    \n",
       "29      29         mikepqr   1 comment                           NaN   \n",
       "..     ...             ...         ...                           ...   \n",
       "180      0         marklit     discuss             (marksblogg.com)    \n",
       "181      1       kokorcsin     discuss                 (data36.com)    \n",
       "182      2   deeplearningt     discuss      (deeplearningtrack.com)    \n",
       "183      3         Soapbox     discuss                  (sp-bx.com)    \n",
       "184      4        lmcinnes     discuss                  (github.io)    \n",
       "185      5         Soapbox     discuss                  (sp-bx.com)    \n",
       "186      6           axelr     discuss                  (github.io)    \n",
       "187      7       cavaunpeu     discuss                (willwolf.io)    \n",
       "188      8         Weenkus     discuss            (datawhatnow.com)    \n",
       "189      9   deeplearningt     discuss      (deeplearningtrack.com)    \n",
       "190     10         blester     discuss             (abigailsee.com)    \n",
       "191     11      jmsmistral  3 comments     (jonathansacramento.com)    \n",
       "192     12     gargisharma     discuss           (paralleldots.com)    \n",
       "193     13   alexandraj777   1 comment                 (sigopt.com)    \n",
       "194     14        enmanuel   1 comment            (blogspot.com.ar)    \n",
       "195     15              Hx     discuss                  (intel.com)    \n",
       "196     16           jahan     discuss               (aioptify.com)    \n",
       "197     17         okcdata     discuss                (okcupid.com)    \n",
       "198     18     gargisharma     discuss           (paralleldots.com)    \n",
       "199     19      Argentum01     discuss           (theintercept.com)    \n",
       "200     20     gargisharma     discuss           (paralleldots.com)    \n",
       "201     21            mapd     discuss                   (mapd.com)    \n",
       "202     22       displayr1     discuss               (displayr.com)    \n",
       "203     23         sergios     discuss         (neuraldesigner.com)    \n",
       "204     24          sqadri   1 comment                (jupyter.org)    \n",
       "205     25     gargisharma     discuss           (paralleldots.com)    \n",
       "206     26  DataScienceInc     discuss            (datascience.com)    \n",
       "207     27   deeplearningt  3 comments      (deeplearningtrack.com)    \n",
       "208     28      adam_alook     discuss         (alookanalytics.com)    \n",
       "209     29        ata_aman     discuss                (datazar.com)    \n",
       "\n",
       "                                                 links     points  \\\n",
       "0    https://explosion.ai/blog/quora-deep-text-pair...   6 points   \n",
       "1    https://labs.opendoor.com/2017/02/17/two-cultu...   4 points   \n",
       "2    http://blog.yhat.com/posts/R-for-excel-users.html   5 points   \n",
       "3    https://medium.com/data36/wannabe-data-scienti...   8 points   \n",
       "4    https://labs.opendoor.com/2017/02/16/building-...   4 points   \n",
       "5    http://urbanspatialanalysis.com/portfolio/pred...   2 points   \n",
       "6    http://data36.com/data-resistance-evangelize-d...   7 points   \n",
       "7                                        item?id=16765   5 points   \n",
       "8    http://willwolf.io/en/2017/02/03/bayesian-esti...   8 points   \n",
       "9    http://www.deeplearningweekly.com/blog/demysti...   9 points   \n",
       "10   http://blog.webhose.io/2017/02/09/how-to-use-r...   6 points   \n",
       "11   http://martin.zinkevich.org/rules_of_ml/rules_...  30 points   \n",
       "12   http://www.scribd.com/vacuum?url=http://martin...   9 points   \n",
       "13   https://research.googleblog.com/2017/02/using-...   5 points   \n",
       "14   http://www.slideshare.net/brainvireinfo/nodejs...   4 points   \n",
       "15   http://blog.datumbox.com/getting-the-gpu-usage...   6 points   \n",
       "16   https://blog.insightdatascience.com/anonymizat...   6 points   \n",
       "17   http://blog.ethanrosenthal.com/2017/02/05/rec-...   6 points   \n",
       "18   http://sharpsightlabs.com/blog/map-geospatial-...   9 points   \n",
       "19          http://tech.marksblogg.com/benchmarks.html  15 points   \n",
       "20   http://christopherroach.com/articles/statistic...   9 points   \n",
       "21   https://blog.alookanalytics.com/2017/01/30/pyt...   3 points   \n",
       "22   http://blog.aylien.com/sentiment-analysis-of-2...   9 points   \n",
       "23   https://medium.com/@kacawi/python-excel-tutori...   2 points   \n",
       "24   http://flovv.github.io/From_descritpive_to_pre...   2 points   \n",
       "25   http://willwolf.io/en/2017/02/07/bayesian-infe...   2 points   \n",
       "26   http://sharpsightlabs.com/blog/human-capital-map/   5 points   \n",
       "27   https://www.mapd.com/blog/2017/02/03/mapd-2-0-...   5 points   \n",
       "28   https://blog.alookanalytics.com/2017/02/05/how...   7 points   \n",
       "29   http://blog.yhat.com/posts/deep-learning-chess...   2 points   \n",
       "..                                                 ...        ...   \n",
       "180  http://tech.marksblogg.com/billion-nyc-taxi-ri...   4 points   \n",
       "181  https://data36.com/learn-data-analytics-bash-s...   2 points   \n",
       "182  https://www.deeplearningtrack.com/single-post/...   8 points   \n",
       "183    https://www.sp-bx.com/getting-grips-blockchain/   3 points   \n",
       "184       http://lmcinnes.github.io/subreddit_mapping/   5 points   \n",
       "185  https://www.sp-bx.com/5-ways-make-business-sma...   2 points   \n",
       "186  http://arogozhnikov.github.io/2017/04/20/machi...  11 points   \n",
       "187  http://willwolf.io/2017/04/19/deriving-the-sof...   2 points   \n",
       "188         http://datawhatnow.com/feature-importance/   6 points   \n",
       "189  https://www.deeplearningtrack.com/single-post/...  15 points   \n",
       "190  http://www.abigailsee.com/2017/04/16/taming-rn...   4 points   \n",
       "191  http://jonathansacramento.com/posts/20170416_c...   6 points   \n",
       "192  http://blog.paralleldots.com/data-scientist/7-...  14 points   \n",
       "193  http://blog.sigopt.com/post/159685042073/sigop...   5 points   \n",
       "194  http://python-apuntes.blogspot.com.ar/2017/04/...   6 points   \n",
       "195  https://software.intel.com/en-us/blogs/2017/04...   4 points   \n",
       "196   http://www.aioptify.com/top-prediction-books.php   4 points   \n",
       "197  https://tech.okcupid.com/the-pitfalls-of-a-b-t...   4 points   \n",
       "198  http://blog.paralleldots.com/technology/deep-l...  10 points   \n",
       "199         https://trial-and-terror.theintercept.com/   2 points   \n",
       "200  http://blog.paralleldots.com/technology/machin...  17 points   \n",
       "201  https://www.mapd.com/blog/2017/04/14/quick-ins...   4 points   \n",
       "202                     https://www.displayr.com/blog/   8 points   \n",
       "203  https://www.neuraldesigner.com/blog/market-bas...   4 points   \n",
       "204  http://blog.jupyter.org/2017/04/04/jupyter-not...  20 points   \n",
       "205  http://blog.paralleldots.com/technology/machin...  20 points   \n",
       "206  https://www.datascience.com/trends/machine-lea...   8 points   \n",
       "207                 https://www.deeplearningtrack.com/  15 points   \n",
       "208  https://blog.alookanalytics.com/2017/04/11/int...   8 points   \n",
       "209  https://blog.datazar.com/announcing-datazar-v2...   2 points   \n",
       "\n",
       "                                                titles  \n",
       "0    Deep text-pair classification with Quora's 201...  \n",
       "1         The Two Cultures of Machine Learning Systems  \n",
       "2                                    R for Excel Users  \n",
       "3    Wannabe Data Scientist! Here are 8 free online...  \n",
       "4    How to keep your data scientists and engineers...  \n",
       "5    Predicting gentrification using longitudinal c...  \n",
       "6    Data-resistance – How to evangelize the data d...  \n",
       "7    Engineered features for dataset boosting for N...  \n",
       "8    RescueTime Estimation via the \"Poor Man's Diri...  \n",
       "9                                Demystifying Word2Vec  \n",
       "10   How to use Webhose.io rated reviews for sentim...  \n",
       "11   \\tBest Practices for ML Engineering from Googl...  \n",
       "12                                              scribd  \n",
       "13   Using Machine Learning to predict parking diff...  \n",
       "14   Advantage of Node.js Development For Business ...  \n",
       "15   Getting the GPU usage of NVIDIA cards with the...  \n",
       "16   Anonymizing documents with Word Vectors and O(...  \n",
       "17   Rec-a-Sketch: a Flask App for Interactive Sket...  \n",
       "18     Beautiful data: mapping USA rivers with ggplot2  \n",
       "19   DB benchmark shootout on 1.2B row NYC taxi dat...  \n",
       "20                              Statistics for Hackers  \n",
       "21   Running Python on the Cloud - essentials for D...  \n",
       "22   Sentiment Analysis of 2.2 million tweets from ...  \n",
       "23              Python and Excel: The Definitive Guide  \n",
       "24          From Descriptive to Prescriptive Analytics  \n",
       "25          Bayesian Inference via Simulated Annealing  \n",
       "26   One thing critical for success in the age of A...  \n",
       "27            How we made GPU-powered MapD even faster  \n",
       "28   How to plot your own bike/jogging route using ...  \n",
       "29                             Deep Learning for Chess  \n",
       "..                                                 ...  \n",
       "180  1.1 Billion Taxi Rides with MapD 3.0 & 2 GPU-P...  \n",
       "181  7 articles to learn basics of Command Line/Bas...  \n",
       "182        Deep Learning intuition for a business user  \n",
       "183                   Getting to grips with Blockchain  \n",
       "184      Mapping and Analysing SubReddits Using Python  \n",
       "185  5 Ways To Make Your Business Smarter Using Aug...  \n",
       "186  Machine Learning in Science and Industry [slides]  \n",
       "187         Deriving the Softmax from First Principles  \n",
       "188          Feature importance and why it's important  \n",
       "189  Learn under the hood of Gradient Descent algor...  \n",
       "190  Abstractive Summary with Pointer-Generator Net...  \n",
       "191          Predicting Churn without Machine Learning  \n",
       "192  7 types of job profiles that make you a Data S...  \n",
       "193        Expected Improvement vs. Knowledge Gradient  \n",
       "194  Python script for create dummies (using \"featu...  \n",
       "195  Intel and Facebook* Collaborate to Boost Caffe...  \n",
       "196                            Top Books on Prediction  \n",
       "197     The pitfalls of A/B testing in social networks  \n",
       "198          Some Lesser-Known Deep Learning Libraries  \n",
       "199  Most people prosecuted for terrorism since 9/1...  \n",
       "200       Some Lesser Known Machine Learning Libraries  \n",
       "201  Quick visual insight with cross-filtering in M...  \n",
       "202     Data science tool in early beta (so it's free)  \n",
       "203  Market Basket Analysis using R and Neural Desi...  \n",
       "204                               Jupyter Notebook 5.0  \n",
       "205  List of Free Must-Read Books for Machine Learning  \n",
       "206  Visualize and share trends in GitHub activity ...  \n",
       "207       An innovative approach to learn data science  \n",
       "208  Intuition vs Unsupervised Learning – Agglomera...  \n",
       "209                              Announcing Datazar v2  \n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def parse_url(url=\"http://www.datatau.com\", data=False):\n",
    "    \n",
    "    response  =  requests.get(url)\n",
    "    links     =  Selector(text=response.text).xpath(\"//td[@class='title']/a/@href\").extract()\n",
    "    titles    =  Selector(text=response.text).xpath(\"//td[@class='title']/a/text()\").extract()\n",
    "    points    =  Selector(text=response.text).xpath(\"//td[@class='subtext']/span/text()\").extract()\n",
    "    domains   =  Selector(text=response.text).xpath(\"//td[@class='title']/span/text()\").extract()\n",
    "    authors   =  Selector(text=response.text).xpath(\"//td[@class='subtext']/a[contains(@href, 'user')]/text()\").extract()\n",
    "    comments  =  Selector(text=response.text).xpath(\"//td[@class='subtext']/a[contains(@href, 'item')]/text()\").extract()\n",
    "\n",
    "    expected_length = 30\n",
    "    \n",
    "    # [np.nan]*(expected_length - len(points)) to the end of the lists, will fill in missing\n",
    "    # values at the end that sometimes don't exist at the ends of the results\n",
    "    scraped = dict(\n",
    "        titles   =  titles[:30], \n",
    "        links    =  links[:30], # :30 because of that damn \"more\" link\n",
    "        points   =  points + [np.nan]*(expected_length - len(points)),\n",
    "        domains  =  domains + [np.nan]*(expected_length - len(domains)),\n",
    "        authors  =  authors + [np.nan]*(expected_length - len(authors)),\n",
    "        comments =  comments + [np.nan]*(expected_length - len(comments))\n",
    "    )\n",
    "    \n",
    "    df = pd.DataFrame(scraped)\n",
    "    \n",
    "    if type(data) != bool:\n",
    "        data = df.append(data)\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    # If there's data append it, if not, it's the first iteration, no need.\n",
    "    # Find more link\n",
    "    more_anchor  =  Selector(text=response.text).xpath(\"//a[text() = 'More']/@href\").extract()\n",
    "    \n",
    "    if len(more_anchor) > 0:\n",
    "        more_url  =  \"http://www.datatau.com%s\" % more_anchor[0]\n",
    "        print \"Fetching %s...\" % more_url\n",
    "        return parse_url(more_url, data=data)\n",
    "    else:\n",
    "        return data.reset_index()\n",
    "       \n",
    "        \n",
    "df = parse_url(\"http://www.datatau.com\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

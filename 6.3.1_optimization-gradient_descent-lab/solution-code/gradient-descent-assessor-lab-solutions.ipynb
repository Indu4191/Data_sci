{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Gradient Descent in Sklearn\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "Until now we've been using specific sklearn model classes to perform regression and classification such as `LinearRegression` and `LogisticRegression`. Unfortunately, while these methods work well on smaller datasets with relatively small numbers of columns, once you start getting into \"Medium Data\" these slow down to a crawl, and take up so much memory that fitting them becomes mind-numbingly slow (especially on a laptop).\n",
    "\n",
    "Luckily, sklearn comes with  stochastic gradient descent solvers for regression and classification:\n",
    "- `SGDRegressor`\n",
    "- `SGDClassifier`\n",
    "\n",
    "Due to its ability to minimize the loss function iteratively on smaller portions of the data, it avoids the intense slowdown other models suffer on large datasets.\n",
    "\n",
    "> **Note:** The gradient descent solvers are very flexible and can fit a variety of different model types not covered here. I highly recommend reading their documentation in detail.\n",
    "\n",
    "---\n",
    "\n",
    "### SF assessor data\n",
    "\n",
    "This lab uses data from the SF assessor's office on housing prices in San Francisco - it's already cleaned up.\n",
    "\n",
    "You can see that the dataset has 250k rows. When expanding this with dummy-coded categorical columns it can become quite large. Be careful that you don't exceed the memory on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import patsy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data.\n",
    "\n",
    "Examine the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop = pd.read_csv('./datasets/assessor_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(754147, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baths               int64\n",
       "beds                int64\n",
       "lot_depth         float64\n",
       "basement_area     float64\n",
       "front_ft          float64\n",
       "owner_pct         float64\n",
       "rooms               int64\n",
       "property_class     object\n",
       "neighborhood       object\n",
       "tax_rate          float64\n",
       "volume              int64\n",
       "sqft                int64\n",
       "stories             int64\n",
       "year_recorded       int64\n",
       "year_built          int64\n",
       "zone               object\n",
       "value             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baths             0\n",
       "beds              0\n",
       "lot_depth         0\n",
       "basement_area     0\n",
       "front_ft          0\n",
       "owner_pct         0\n",
       "rooms             0\n",
       "property_class    0\n",
       "neighborhood      0\n",
       "tax_rate          0\n",
       "volume            0\n",
       "sqft              0\n",
       "stories           0\n",
       "year_recorded     0\n",
       "year_built        0\n",
       "zone              0\n",
       "value             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Z', 'D', 'ZBM', 'DBM', 'LZ', 'TH'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.property_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['08E', '08G', '08D', '08H', '08C', '08B', '08A', '08I', '07A',\n",
       "       '07D', '07B', '08F', '06C', '06D', '06E', '06B', '06A', '07C',\n",
       "       '01C', '01G', '06F', '05B', '05F', '05E', '05H', '01F', '01D',\n",
       "       '01E', '01A', '01B', '02C', '02E', '02F', '02A', '02B', '02D',\n",
       "       '02G', '04C', '04T', '03C', '05J', '05G', '04D', '05K', '05D',\n",
       "       '04F', '05C', '04J', '04H', '047', '04K', '04G', '04P', '04S',\n",
       "       '04M', '04N', '04R', '10H', '04A', '05M', '09F', '09C', '09H',\n",
       "       '09B', '09D', '09E', '10J', '10A', '10K', '10G', '10F', '09A',\n",
       "       '09G', '10C', '10E', '10B', '05A', '04B', '04E', '03H', '10D',\n",
       "       '03B', '03J', '03G', '03F', '03A', '03E', '03D'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.neighborhood.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sample down the data\n",
    "\n",
    "Despite this already being a sample of the full assessor dataset, you should sample the data down further the sake of speed and your computers memory.\n",
    "\n",
    "Use the `.sample()` function for pandas dataframes to subset this down to < 25000 rows. \n",
    "\n",
    "Sampling down large datasets is a common procedure. Finding the optimal parameters with larger subsets of the data may change the hyperparameters and the results, and will get you closer to the best coefficients, but the returns are marginal at a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_samp = prop.sample(n=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regression with stochastic gradient descent\n",
    "\n",
    "Below I set up X, y data predicting value (housing price) from the remaining variables. There are ~75,000 rows, with 170 columns.\n",
    "\n",
    "\n",
    "The `SGDRegressor` is very general and flexible, and can be customized with a variety of keyword arguments.\n",
    "\n",
    "**Arguments**\n",
    "- `loss`: `['squared_loss','huber', ...]`\n",
    "    - The `'squared_loss'` loss corresponds to solving a regression with the least squares loss. This is what I expect you'll use, but there are other options. Huber loss is a \"robust\" regression loss.\n",
    "- `penalty`: `['none','l1','l2','elasticnet']`\n",
    "    - This defines the penalty on the regression that you would like to solve. The l1 and l2 are the Lasso and Ridge, while the elasticnet is the combination of them both.\n",
    "- `alpha`\n",
    "    - The regularization strength to be used with a chosen penalty. Same as in Lasso and Ridge.\n",
    "- `l1_ratio`\n",
    "    - The mix of the Lasso and Ridge penalties when elasticnet is chosen as the penalty.\n",
    "- `n_iter`\n",
    "    - The number of training \"epochs\" over the data. This is the number of passes that the gradient descent algorithm will make over the data to iteratively fit the weights (defaults to 5).\n",
    "\n",
    "`SGDRegressor` is most often used in tandem with grid searching to find the optimal parameters for certain models. \n",
    "\n",
    "**It is up to you how you want to define the model. You should:**\n",
    "\n",
    "1. Choose a target to estimate (this should be continuous).\n",
    "- Select predictors to use.\n",
    "- Standardize your predictor matrix.\n",
    "- Build a stochastic gradient descent solver to fit your model. You will likely want to do some kind of gridsearch to find the optimal parameters for your model.\n",
    "- Describe the model selected through gridsearch and compare the performance to baseline.\n",
    "- Examine and interpret the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value ~ baths + beds + lot_depth + basement_area + front_ft + owner_pct + rooms + property_class + neighborhood + tax_rate + volume + sqft + stories + year_recorded + year_built + zone -1\n",
      "(25000,) (25000, 163)\n"
     ]
    }
   ],
   "source": [
    "f = 'value ~ '+' + '.join([c for c in prop_samp.columns if not c == 'value'])+' -1'\n",
    "print f\n",
    "y, X = patsy.dmatrices(f, data=prop_samp, return_type='dataframe')\n",
    "y = y.values.ravel()\n",
    "\n",
    "print y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am predicting the value of the house from the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor, SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 163)\n"
     ]
    }
   ],
   "source": [
    "# standardize the predictors\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "print Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up my gridsearch parameters:\n",
    "sgd_params = {\n",
    "    'loss':['squared_loss','huber'],\n",
    "    'penalty':['l1','l2'],\n",
    "    'alpha':np.logspace(-5,1,25)\n",
    "}\n",
    "\n",
    "sgd_reg = SGDRegressor()\n",
    "sgd_reg_gs = GridSearchCV(sgd_reg, sgd_params, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'loss': ['squared_loss', 'huber'], 'alpha': array([  1.00000e-05,   1.77828e-05,   3.16228e-05,   5.62341e-05,\n",
       "         1.00000e-04,   1.77828e-04,   3.16228e-04,   5.62341e-04,\n",
       "         1.00000e-03,   1.77828e-03,   3.16228e-03,   5.62341e-03,\n",
       "         1.00000e-...2341e-01,\n",
       "         1.00000e+00,   1.77828e+00,   3.16228e+00,   5.62341e+00,\n",
       "         1.00000e+01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD is pretty fast compared to other sklearn solvers - but can still\n",
    "# take a good long while depending on the gridsearch and the size of\n",
    "# the dataset.\n",
    "sgd_reg_gs.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'alpha': 0.56234132519034907, 'loss': 'squared_loss'}\n",
      "0.227204132061\n"
     ]
    }
   ],
   "source": [
    "print sgd_reg_gs.best_params_\n",
    "print sgd_reg_gs.best_score_\n",
    "sgd_reg = sgd_reg_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can see that the gradient descent got a .22 R2 using the ridge and squared loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>mag</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>45564.228979</td>\n",
       "      <td>45564.228979</td>\n",
       "      <td>beds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>32631.977463</td>\n",
       "      <td>32631.977463</td>\n",
       "      <td>sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>28652.346605</td>\n",
       "      <td>28652.346605</td>\n",
       "      <td>neighborhood[T.08E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-28189.115056</td>\n",
       "      <td>28189.115056</td>\n",
       "      <td>owner_pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>24717.889344</td>\n",
       "      <td>24717.889344</td>\n",
       "      <td>year_recorded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>23467.877598</td>\n",
       "      <td>23467.877598</td>\n",
       "      <td>neighborhood[T.05H]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>23101.318589</td>\n",
       "      <td>23101.318589</td>\n",
       "      <td>neighborhood[T.07A]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>23091.664374</td>\n",
       "      <td>23091.664374</td>\n",
       "      <td>baths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>23034.538664</td>\n",
       "      <td>23034.538664</td>\n",
       "      <td>neighborhood[T.07B]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>22842.291333</td>\n",
       "      <td>22842.291333</td>\n",
       "      <td>neighborhood[T.05C]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef           mag                 pred\n",
       "151  45564.228979  45564.228979                 beds\n",
       "159  32631.977463  32631.977463                 sqft\n",
       "70   28652.346605  28652.346605  neighborhood[T.08E]\n",
       "155 -28189.115056  28189.115056            owner_pct\n",
       "161  24717.889344  24717.889344        year_recorded\n",
       "52   23467.877598  23467.877598  neighborhood[T.05H]\n",
       "62   23101.318589  23101.318589  neighborhood[T.07A]\n",
       "150  23091.664374  23091.664374                baths\n",
       "63   23034.538664  23034.538664  neighborhood[T.07B]\n",
       "47   22842.291333  22842.291333  neighborhood[T.05C]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_coefs = pd.DataFrame({'coef':sgd_reg.coef_,\n",
    "                            'mag':np.abs(sgd_reg.coef_),\n",
    "                            'pred':X.columns})\n",
    "value_coefs.sort_values('mag', ascending=False, inplace=True)\n",
    "value_coefs.iloc[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Classification with stochastic gradient descent\n",
    "\n",
    "The `SGDClassifier` is very similar to the `SGDRegressor`. The main difference is that the loss functions are changed to regression loss functions.\n",
    "\n",
    "**Arguments**\n",
    "- `loss`: `['log', ...]`\n",
    "    - The `'log'` loss corresponds to solving a logistic regression classifier. This is what I expect you'll use, but there are many other options.\n",
    "- `penalty`: `['none','l1','l2','elasticnet']`\n",
    "    - This defines the penalty on the regression that you would like to solve. The l1 and l2 are the Lasso and Ridge, while the elasticnet is the combination of them both.\n",
    "- `alpha`\n",
    "    - The regularization strength to be used with a chosen penalty. Same as in Lasso and Ridge.\n",
    "- `l1_ratio`\n",
    "    - The mix of the Lasso and Ridge penalties when elasticnet is chosen as the penalty.\n",
    "- `n_iter`\n",
    "    - The number of training \"epochs\" over the data. This is the number of passes that the gradient descent algorithm will make over the data to iteratively fit the weights (defaults to 5).\n",
    "\n",
    "Like `SGDRegressor`, `SGDClassifier` is most often used in tandem with grid searching to find the optimal parameters for certain models. \n",
    "\n",
    "**It is up to you how you want to define the model. You should:**\n",
    "\n",
    "1. Choose a target to classify (you may need to engineer one from existing variables).\n",
    "- Calculate the baseline accuracy.\n",
    "- Select predictors to use.\n",
    "- Standardize your predictor matrix.\n",
    "- Build a stochastic gradient descent solver to fit your model. You will likely want to do some kind of gridsearch to find the optimal parameters for your model.\n",
    "- Describe the model selected through gridsearch and compare the performance to baseline.\n",
    "- Examine and interpret the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'baths', u'beds', u'lot_depth', u'basement_area', u'front_ft',\n",
       "       u'owner_pct', u'rooms', u'property_class', u'neighborhood', u'tax_rate',\n",
       "       u'volume', u'sqft', u'stories', u'year_recorded', u'year_built',\n",
       "       u'zone', u'value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_samp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1941    965\n",
       "1940    927\n",
       "1925    910\n",
       "1924    801\n",
       "1926    775\n",
       "1927    731\n",
       "1939    633\n",
       "1923    623\n",
       "1948    567\n",
       "1947    530\n",
       "1908    529\n",
       "1928    500\n",
       "1922    445\n",
       "1938    444\n",
       "1950    443\n",
       "1906    419\n",
       "1946    416\n",
       "1907    402\n",
       "1931    394\n",
       "1951    389\n",
       "1930    345\n",
       "1910    344\n",
       "1936    338\n",
       "1949    337\n",
       "1929    335\n",
       "1944    333\n",
       "1937    332\n",
       "1912    305\n",
       "1942    301\n",
       "1945    272\n",
       "       ... \n",
       "1996    112\n",
       "1997    105\n",
       "1933     96\n",
       "1993     95\n",
       "1998     87\n",
       "1995     81\n",
       "1985     81\n",
       "1918     77\n",
       "1994     74\n",
       "1977     74\n",
       "1976     70\n",
       "1970     66\n",
       "1902     65\n",
       "1973     62\n",
       "1966     61\n",
       "1974     55\n",
       "1968     49\n",
       "2000     46\n",
       "1967     46\n",
       "1903     42\n",
       "1934     34\n",
       "1971     34\n",
       "1969     30\n",
       "1999     13\n",
       "1901     11\n",
       "2003      5\n",
       "2009      3\n",
       "2001      2\n",
       "2004      2\n",
       "2006      1\n",
       "Name: year_built, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_samp.year_built.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets see if we can predict if a house was built past 1980\n",
    "prop_samp['built_past1980'] = prop_samp.year_built.map(lambda x: 1 if x >= 1980 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89824\n"
     ]
    }
   ],
   "source": [
    "# make the target and calculate the baseline:\n",
    "y = prop_samp.built_past1980.values\n",
    "print 1. - np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = '''\n",
    "~ baths + beds + lot_depth + basement_area + front_ft + owner_pct +\n",
    "rooms + property_class + neighborhood + tax_rate + volume + sqft + stories +\n",
    "zone + value -1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000, 162)\n"
     ]
    }
   ],
   "source": [
    "X = patsy.dmatrix(f, data=prop_samp, return_type='dataframe')\n",
    "\n",
    "Xs = ss.fit_transform(X)\n",
    "print y.shape, Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_cls_params = {\n",
    "    'loss':['log'],\n",
    "    'penalty':['l1','l2'],\n",
    "    'alpha':np.logspace(-5,2,50)\n",
    "}\n",
    "\n",
    "sgd_cls = SGDClassifier()\n",
    "sgd_cls_gs = GridSearchCV(sgd_cls, sgd_cls_params, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   56.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'loss': ['log'], 'alpha': array([  1.00000e-05,   1.38950e-05,   1.93070e-05,   2.68270e-05,\n",
       "         3.72759e-05,   5.17947e-05,   7.19686e-05,   1.00000e-04,\n",
       "         1.38950e-04,   1.93070e-04,   2.68270e-04,   3.72759e-04,\n",
       "         5.17947e-04,   7.19686e-04,...    1.93070e+01,   2.68270e+01,   3.72759e+01,   5.17947e+01,\n",
       "         7.19686e+01,   1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_cls_gs.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'alpha': 7.1968567300115141e-05, 'loss': 'log'}\n",
      "0.96464\n"
     ]
    }
   ],
   "source": [
    "print sgd_cls_gs.best_params_\n",
    "print sgd_cls_gs.best_score_\n",
    "sgd_cls = sgd_cls_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

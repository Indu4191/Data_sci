{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Object Oriented Programming: Coding a Linear Regression Class\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Learn the fundamentals of object oriented programming in python\n",
    "- Review the solution to coefficients for multiple linear regression\n",
    "- Apply object oriented programming concepts to build a linear regression class by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Review the linear algebra derivation of coefficients for MLR](#review-mlr)\n",
    "- [Load the simple housing data](#load-data)\n",
    "- [Classes and objects](#classes-objects)\n",
    "- [Coding our own `LinearRegression` class](#coding-lr)\n",
    "    - [Starting a basic python class](#starting-class)\n",
    "    - [Adding a class function](#class-function)\n",
    "    - [Assigning attributes during instantiation](#init-args)\n",
    "    - [Add another function to add an intercept](#intercept-adder)\n",
    "    - [Instantiate the class](#instantiate)\n",
    "    - [Add a predict function](#predict)\n",
    "    - [Add a score function](#score)\n",
    "- [Verify your class against the sklearn implementation](#verify)\n",
    "- [Inspecting a class](#inspection)\n",
    "- [Some special class methods](#special)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review-mlr'></a>\n",
    "\n",
    "## Review: solving for the coefficients that minimize the loss\n",
    "\n",
    "---\n",
    "\n",
    "### The \"least squares\" solution to linear regression\n",
    "\n",
    "**Step 1:** With target vector $y$ and prediction matrix $X$, we can formulate a regression as:\n",
    "\n",
    "### $$ y = \\beta X + \\epsilon $$\n",
    "\n",
    "Where $\\beta$ is our vector of coefficients and $\\epsilon$ is our vector of errors, or residuals.\n",
    "\n",
    "**Step 2:** We can equivalently formulate this as a calculation of the residuals:\n",
    "\n",
    "### $$ \\epsilon = \\beta X - y $$\n",
    "\n",
    "*Our goal is to minimize the sum of squared residuals.* This is also known as the \"least squares loss function\". \n",
    "\n",
    "**Step 3:** Solve for the sum of squared residuals on the left side of the equation. Recall the vector of errors are equivalent to the residuals. The sum of squared residuals is represented as the dot product of the vector of residuals.\n",
    "\n",
    "### $$ \\sum_{i=1}^n \\epsilon_i^2 = \n",
    "\\left[\\begin{array}{cc}\n",
    "\\epsilon_1 \\cdots \\epsilon_n\n",
    "\\end{array}\\right] \n",
    "\\left[\\begin{array}{cc}\n",
    "\\epsilon_1 \\\\ \\cdots \\\\ \\epsilon_n\n",
    "\\end{array}\\right] = \\epsilon' \\epsilon\n",
    "$$\n",
    "\n",
    "Therefore we can write the sum of squared residuals as:\n",
    "\n",
    "### $$ \\epsilon' \\epsilon = (\\beta X - y)' (\\beta X - y) $$\n",
    "\n",
    "Which becomes:\n",
    "\n",
    "### $$ \\epsilon' \\epsilon = y'y - y'X\\beta - \\beta' X' y + \\beta' X' X \\beta $$\n",
    "\n",
    "**Step 4:** We want to find the coefficients where the loss function will be minimum. In this case we can use calculus, taking the derivative with respect to the $\\beta$ vector:\n",
    "\n",
    "### $$ \\frac{\\partial \\epsilon' \\epsilon}{\\partial \\beta} = \n",
    "-2X'y + 2X'X\\beta$$\n",
    "\n",
    "Since want to minimize loss function and the loss function is convex, we set the derivative to zero and solve for the beta coefficient vector:\n",
    "\n",
    "### $$ 0 = -2X'y + 2X'X\\beta \\\\\n",
    "X'X\\beta = X'y \\\\\n",
    "\\beta = (X'X)^{-1}X'y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-data'></a>\n",
    "\n",
    "## Load the simple housing data\n",
    "\n",
    "---\n",
    "\n",
    "This dataset only has 4 columns. We can formulate simple regression problems with it to test our linear regression class down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house = './datasets/housing-data.csv'\n",
    "house = pd.read_csv(house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classes-objects'></a>\n",
    "\n",
    "## Classes and objects\n",
    "\n",
    "---\n",
    "\n",
    "In python, everything is an \"object\" of some type. This is the basis of what is known as **Object Oriented Programming (OOP)**.\n",
    "\n",
    "A *class* is a type of object. You can think of a class definition as a sort of \"blueprint\" that specifies the construction of a new object when instantiated.\n",
    "\n",
    "> **Note:** Knowing how to define and use classes is essential to programming python at an intermediate or advanced level. I will cover the basics here, which will help you understand how things like `LinearRegression` in sklearn work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='coding-lr'></a>\n",
    "\n",
    "## Coding our own version of the sklearn `LinearRegression` class\n",
    "\n",
    "---\n",
    "\n",
    "By now you are familiar with the `LinearRegression` class in sklearn. We will walk through the re-creation of this class (albeit a simplified version).\n",
    "\n",
    "\n",
    "<a id='starting-class'></a>\n",
    "### 1. Starting a basic python class\n",
    "\n",
    "Below is the beginning of our class blueprint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the components of this?\n",
    "\n",
    "**`class`**\n",
    "\n",
    "- The `class` is like `def`, but instead of defining a function it defines a class.\n",
    "\n",
    "**`object`**\n",
    "\n",
    "- `object` in the parentheses of the class definition indicate that this class \"inherits\" from the `object` class. The object class is a very general, very fundamental class in python. Inheritance means that whatever properties and function are part of the `object` class are passed down to our `SimpleLinearRegression` class.\n",
    "\n",
    "**`def __init__(self)`**\n",
    "\n",
    "- The `def __init__(self):` is our class's initialization function. This function is called when you instantiate the class by typing `SimpleLinearRegression()`\n",
    "\n",
    "**`self`**\n",
    "\n",
    "- `self` is the first argument to class definitions. It is a variable that refers to the **current instantiation of the class**. What does this mean? When you instantiate a class and assign it to a variable with `slr = SimpleLinearRegression()`, the `self` argument is now a reference to the current instantiation of the class `slr`. Now, when you use a function that is part of the class, it knows to use that specific object's function. This lets you have multiple instantiations of a class with the same function name.\n",
    "\n",
    "**class attributes**\n",
    "\n",
    "- `self.coef_` and `self.intercept_`, likewise, are \"attributes\" (variables) that are connected to the instantiation of the class. When self becomes `slr`, for example, the `self` becomes `slr` and `self.coef_` becomes `slr.coef`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called parents init\n",
      "3\n",
      "<__main__.DumbChild object at 0x1043f3f50>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Below is a dumb example of class inheritance.\n",
    "'''\n",
    "\n",
    "class DumbClass(object):\n",
    "    \n",
    "    variable_parent = 10\n",
    "    \n",
    "    def __init__(self, set_variable=1):\n",
    "        self.variable = set_variable\n",
    "        \n",
    "    def multiply_variable(self, multiplier):\n",
    "        return multiplier\n",
    "    \n",
    "    \n",
    "class DumbChild(DumbClass):\n",
    "    \"\"\"\n",
    "    My documentation for this class.\n",
    "    \n",
    "    Functions:\n",
    "        print_hello\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, set_variable=2):\n",
    "        super(DumbChild, self).__init__(set_variable=set_variable)        \n",
    "        print 'called parents init'\n",
    "    \n",
    "    def print_hello(self):\n",
    "        print self\n",
    "        \n",
    "child = DumbChild(set_variable=3)\n",
    "print child.variable\n",
    "child.print_hello()\n",
    "child.multiply_variable(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='class-function'></a>\n",
    "### 2. Adding a class function\n",
    "\n",
    "Now, just like with `__init__`, we can add functions to the class.\n",
    "\n",
    "**Let's add a `fit()` method that will calculate the coefficients for a linear regression.**\n",
    "- The function should have arguments `self`, `X` and `y`.\n",
    "- Use the linear algebra equations above to calculate the coefficients and intercept.\n",
    "- Assign the coefficients to `self.coef_` and the intercept to `self.intercept_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # betas formula\n",
    "        # betas = (X'X)^-1 X'Y\n",
    "        \n",
    "        XtX = np.dot(X.T, X)\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "        XtX_inv_Xt = np.dot(XtX_inv, X.T)\n",
    "        self.coef_ = np.dot(XtX_inv_Xt, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we assigned `self.coef_` inside of the `fit()` function.\n",
    "\n",
    "This will set the class attribute `self.coef_`, and this attribute can be accessed by _any other function in the class without passing it as an argument!_\n",
    "\n",
    "It can also be accessed by you after instantiating the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='init-args'></a>\n",
    "### 3. Assigning attributes during instantiation\n",
    "\n",
    "There is an issue here - we may pass an `X` matrix in without an intercept. \n",
    "\n",
    "**Add a keyword argument to the `__init__` function which will specify whether the `X` matrix should have an intercept added or not.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(object):\n",
    "    \n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # betas formula\n",
    "        # betas = (X'X)^-1 X'Y\n",
    "        \n",
    "        XtX = np.dot(X.T, X)\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "        XtX_inv_Xt = np.dot(XtX_inv, X.T)\n",
    "        self.coef_ = np.dot(XtX_inv_Xt, y)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, if we instantiate the class, it will assign `fit_intercept` to the class attribute `fit_intercept`. Try it out:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slr = SimpleLinearRegression(fit_intercept=True)\n",
    "slr.fit_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slr = SimpleLinearRegression(fit_intercept=False)\n",
    "slr.fit_intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='intercept-adder'></a>\n",
    "### 4. Add a function to add an intercept to the `X` matrix if necessary\n",
    "\n",
    "This function will be called from inside the `fit` function and run conditional on the value of `self.fit_intercept`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(object):\n",
    "    \n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate([intercept, X], axis=1)\n",
    "        return X\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        \n",
    "        # betas formula\n",
    "        # betas = (X'X)^-1 X'Y\n",
    "        \n",
    "        XtX = np.dot(X.T, X)\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "        XtX_inv_Xt = np.dot(XtX_inv, X.T)\n",
    "        betas = np.dot(XtX_inv_Xt, y)\n",
    "        \n",
    "        self.coef_ = betas[1:]\n",
    "        self.intercept_ = betas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='instantiate'></a>\n",
    "### 5. Instantiate the class\n",
    "\n",
    "At this point we can try out our class. \n",
    "\n",
    "**Instantiate the class and try out the coefficient fitting function on the housing data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = house.price.values\n",
    "X = house[['sqft','bdrms','age']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "slr = SimpleLinearRegression(fit_intercept=True)\n",
    "print slr.fit_intercept\n",
    "print slr.coef_\n",
    "print slr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  139.33484671 -8621.47045953   -81.21787764]\n",
      "92451.6278416\n"
     ]
    }
   ],
   "source": [
    "print slr.coef_\n",
    "print slr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in the sklearn `LinearRegression` class, we now have access to the assigned `coef_` and `intercept_` attributes after fitting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='predict'></a>\n",
    "### 6. Add the `predict` function.\n",
    "\n",
    "Let's add some more of the class methods that are in the real `LinearRegression` class.\n",
    "\n",
    "**First off, add the `predict` function. It will take a design matrix `X` and return predictions for those rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(object):\n",
    "    \n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate([intercept, X], axis=1)\n",
    "        return X\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        \n",
    "        # betas formula\n",
    "        # betas = (X'X)^-1 X'Y\n",
    "        \n",
    "        XtX = np.dot(X.T, X)\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "        XtX_inv_Xt = np.dot(XtX_inv, X.T)\n",
    "        betas = np.dot(XtX_inv_Xt, y)\n",
    "        \n",
    "        self.coef_ = betas[1:]\n",
    "        self.intercept_ = betas[0]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "            \n",
    "        return np.dot(X, np.concatenate([[self.intercept_], self.coef_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test out the predict function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slr = SimpleLinearRegression(fit_intercept=True)\n",
    "slr.fit(X,y)\n",
    "y_hat = slr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47,) (47,)\n"
     ]
    }
   ],
   "source": [
    "print y.shape, y_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='score'></a>\n",
    "### 7. Add a `score` function\n",
    "\n",
    "This will calculate the $R^2$ of your model on a provided `X` and `y`.\n",
    "\n",
    "> **Note:** You'll probably want to write a helper function to calculate the sum of squared errors, since this will be run for both the baseline model and the regression model in order to calculate the $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(object):\n",
    "    \n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate([intercept, X], axis=1)\n",
    "        return X\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        \n",
    "        # betas formula\n",
    "        # betas = (X'X)^-1 X'Y\n",
    "        \n",
    "        XtX = np.dot(X.T, X)\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "        XtX_inv_Xt = np.dot(XtX_inv, X.T)\n",
    "        betas = np.dot(XtX_inv_Xt, y)\n",
    "        \n",
    "        self.coef_ = betas[1:]\n",
    "        self.intercept_ = betas[0]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "            \n",
    "        return np.dot(X, np.concatenate([[self.intercept_], self.coef_]))\n",
    "    \n",
    "    def _calculate_sse(self, y_true, y_hat):\n",
    "        return np.sum((y_true - y_hat)**2)\n",
    "        \n",
    "    def _calculate_r2(self, sse_model, sse_baseline):\n",
    "        return 1. - float(sse_model)/sse_baseline\n",
    "    \n",
    "    def score(self, X, y):\n",
    "            \n",
    "        baseline_sse = self._calculate_sse(y, np.tile(np.mean(y), len(y)))\n",
    "        \n",
    "        y_hat = self.predict(X)\n",
    "        model_sse = self._calculate_sse(y, y_hat)\n",
    "        \n",
    "        return self._calculate_r2(model_sse, baseline_sse)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.733163999069\n"
     ]
    }
   ],
   "source": [
    "slr = SimpleLinearRegression(fit_intercept=True)\n",
    "slr.fit(X,y)\n",
    "r2 = slr.score(X, y)\n",
    "print r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='verify'></a>\n",
    "\n",
    "## Verify your class against the sklearn `LinearRegression` implementation.\n",
    "\n",
    "---\n",
    "\n",
    "Our class should return the same results for the $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73316399906900243"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inspection'></a>\n",
    "\n",
    "## Inspecting a class\n",
    "\n",
    "---\n",
    "\n",
    "When we want to know more about a class object, we can use the \"inspect\" module. Specifically the `inspect.getmembers()` function takes an instantiated class as an argument and returns an information dictionary.\n",
    "\n",
    "This can be helpful to know what attributes and methods are avaiable and basically, the blueprint of a class object in memory.  Depending on the way the class was implemented, you can usually find useful information hiding inside of `slr.__class__.__dict__` -- which can be easier to look at.  The \"right way\" is to use the \"inspect\" module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__class__', __main__.SimpleLinearRegression),\n",
       " ('__delattr__',\n",
       "  <method-wrapper '__delattr__' of SimpleLinearRegression object at 0x114f58c90>),\n",
       " ('__dict__',\n",
       "  {'coef_': array([  139.33484671, -8621.47045953,   -81.21787764]),\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': 92451.627841645211}),\n",
       " ('__doc__', None),\n",
       " ('__format__', <function __format__>),\n",
       " ('__getattribute__',\n",
       "  <method-wrapper '__getattribute__' of SimpleLinearRegression object at 0x114f58c90>),\n",
       " ('__hash__',\n",
       "  <method-wrapper '__hash__' of SimpleLinearRegression object at 0x114f58c90>),\n",
       " ('__init__',\n",
       "  <bound method SimpleLinearRegression.__init__ of <__main__.SimpleLinearRegression object at 0x114f58c90>>),\n",
       " ('__module__', '__main__'),\n",
       " ('__new__', <function __new__>),\n",
       " ('__reduce__', <function __reduce__>),\n",
       " ('__reduce_ex__', <function __reduce_ex__>),\n",
       " ('__repr__',\n",
       "  <method-wrapper '__repr__' of SimpleLinearRegression object at 0x114f58c90>),\n",
       " ('__setattr__',\n",
       "  <method-wrapper '__setattr__' of SimpleLinearRegression object at 0x114f58c90>),\n",
       " ('__sizeof__', <function __sizeof__>),\n",
       " ('__str__',\n",
       "  <method-wrapper '__str__' of SimpleLinearRegression object at 0x114f58c90>),\n",
       " ('__subclasshook__', <function __subclasshook__>),\n",
       " ('__weakref__', None),\n",
       " ('_calculate_r2',\n",
       "  <bound method SimpleLinearRegression._calculate_r2 of <__main__.SimpleLinearRegression object at 0x114f58c90>>),\n",
       " ('_calculate_sse',\n",
       "  <bound method SimpleLinearRegression._calculate_sse of <__main__.SimpleLinearRegression object at 0x114f58c90>>),\n",
       " ('add_intercept',\n",
       "  <bound method SimpleLinearRegression.add_intercept of <__main__.SimpleLinearRegression object at 0x114f58c90>>),\n",
       " ('coef_', array([  139.33484671, -8621.47045953,   -81.21787764])),\n",
       " ('fit',\n",
       "  <bound method SimpleLinearRegression.fit of <__main__.SimpleLinearRegression object at 0x114f58c90>>),\n",
       " ('fit_intercept', True),\n",
       " ('intercept_', 92451.627841645211),\n",
       " ('predict',\n",
       "  <bound method SimpleLinearRegression.predict of <__main__.SimpleLinearRegression object at 0x114f58c90>>),\n",
       " ('score',\n",
       "  <bound method SimpleLinearRegression.score of <__main__.SimpleLinearRegression object at 0x114f58c90>>)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getmembers(slr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='special'></a>\n",
    "\n",
    "## Some special class methods\n",
    "\n",
    "---\n",
    "\n",
    "|Method| Description|\n",
    "|--|--|\n",
    "|\\_\\_init\\_\\_ ( self [,args...] )| Constructor (with any optional arguments) Sample Call : obj = className(args)\n",
    "|\\_\\_del\\_\\_( self ) | Destructor, deletes an object Sample Call : del obj\n",
    "|\\_\\_repr\\_\\_( self ) | Evaluatable string representation Sample Call : repr(obj)\n",
    "|\\_\\_str\\_\\_( self ) | Printable string representation Sample Call : str(obj)\n",
    "|\\_\\_cmp\\_\\_ ( self, x ) | Object comparison Sample Call : cmp(obj, x)\n",
    "\n",
    "The `__repr__` function reports back something descriptive about what the class represents.  You can basically do whatever you want with it but the purpose of it is to convey something descirptive about your class.\n",
    "\n",
    "The `__del__` method is the bookend function of `__init__`. You can use it to run code once your class is done executing.  \n",
    "\n",
    "Generally it works well but in practice there are a few things watch out for.  Read more about [safely using Python destructors](http://eli.thegreenplace.net/2009/06/12/safely-using-destructors-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

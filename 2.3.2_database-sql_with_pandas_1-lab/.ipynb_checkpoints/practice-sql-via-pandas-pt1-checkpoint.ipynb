{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Practice SQL with Pandas pt. 1\n",
    "\n",
    "_Authors: Joseph Nelson (DC), Matt Brems (DC)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: Pandas and SQL\n",
    "\n",
    "\n",
    "#### The pandas connector and functions for SQL\n",
    "\n",
    "We can use SQL through pandas using the `pandas.io.sql` module:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "\n",
    "cars = pd.read_csv('data/csv/car-names.csv', encoding = 'utf-8')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read_sql_table(table_name, con[, schema, ...])\n",
    "    - Read SQL database table into a DataFrame.\n",
    "#### read_sql_query(sql, con[, index_col, ...])\n",
    "    - Read SQL query into a DataFrame.\n",
    "#### read_sql(sql, con[, index_col, ...])\n",
    "    - Read SQL query or database table into a DataFrame.\n",
    "    - a convenience wrapper around read_sql_table() and read_sql_query()\n",
    "    - will delegate to specific function depending on the provided input\n",
    "#### DataFrame.to_sql(name, con[, flavor, ...])\n",
    "    - Write records stored in a DataFrame to a SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.  Create a SQL DB and tables using Pandas DFs and CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First we will need to read our CSV files into Python before we can use Python to convert it to a SQL style dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "\n",
    "cars = pd.read_csv('./datasets/csv/car-names.csv', encoding = 'utf-8')\n",
    "# If you don't specify the type encoding as 'utf-8' you're going to have a bad time when you try to convert to SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the `sqlite3` package and connect to the database.**\n",
    "\n",
    "```python\n",
    "connection = sqlite3.connect('./datasets/sql/Cars.db.sqlite')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the loaded csv to a sql file.\n",
    "\n",
    "```python\n",
    "cars.to_sql(name = 'car_names', con = connection, if_exists = 'replace', index = False)\n",
    "```\n",
    "\n",
    "Important `.to_sql` arguments:\n",
    "- `name` = name of the database useful if you have multiple tables in a SQL database\n",
    "- `con` = the connection path to where the data should be placed\n",
    "- `if_exists` = condition to pass if the database already exists.\n",
    "\n",
    "If you check that directory now you should see an 'Cars.db' sql file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Using the below will allow you to acess a database store in memory(RAM) as opposed to in Storage, if you wanted a temporary SQL database\n",
    "\n",
    "``` python\n",
    "conn = sqlite3.connect(':memory:')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a table in the cars database for car makers.\n",
    "\n",
    "The table should be called `car_makers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a table in the cars database for the car data.\n",
    "\n",
    "The table should be called `car_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using a query string, read the entire `car_names` table from your SQL database to a dataframe\n",
    "\n",
    "Reading into a dataframe with a query string can be done with:\n",
    "```python\n",
    "# Using the read_sql from the Pandas SQL library and setting it equal to a DF object.\n",
    "cars = sql.read_sql(query_string, con = connection)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Tip:** If you 'shift+tab' in the function call, you can see that the `read_sql` function takes the arguments 'sql' and 'con'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side note: normalized vs. denormalized databases\n",
    "\n",
    "---\n",
    "\n",
    "There are several ways to organize data in a relational database. Two common definitions for data setups are: normalized and denormalized.\n",
    "\n",
    "- __Normalized__ structures have a single table per entity, and use many foreign keys or link tables to connect the entities.\n",
    "\n",
    "- __Denormalized__ tables have fewer tables and may (for example) place all of the tweets and the information on users in one table.\n",
    "\n",
    "Each style has advantages and disadvantages. Denormalized tables duplicate a lot of information. For example, in a combined tweets/users table, we may store the address of each user. Now instead of storing this once per user, we are storing this once per tweet!\n",
    "\n",
    "However, this makes the data easy to access if we ever need to find the tweet along with the user's location.\n",
    "\n",
    "Normalized tables save the storage space by separating the information. However, if we ever need to access those two pieces of information, we would need to join the two tables, which can be a fairly slow operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a python function to query a database using pandas and return a dataframe\n",
    "\n",
    "The function should take two arguments:\n",
    "- the query string\n",
    "- the datbase connection object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Select the first 5 rows of the `car_names` table\n",
    "\n",
    "> Hint: the LIMIT command in SQL can limit the number of rows returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Add the cars into the `car_names` table\n",
    "\n",
    "The execute function will come in handy here. It will execute a sql command string.\n",
    "```python\n",
    "connection.execute()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ferrari = (None, 'Ferrari','The Ferrari')\n",
    "tesla = [None, 'Tesla', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Query the `car_names` table for all columns where `'Model' = 'Tesla'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Select the first 5 rows from the `car_makers` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Select the first 5 rows from the `car_data` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SQL join types\n",
    "\n",
    "---\n",
    "\n",
    "SQL joins are used when data is spread in different tables. A join operation allows to combine rows from two or more tables in a single new table. In order for this to be possible, a common field between the tables need to exist.\n",
    "\n",
    "Join operations can be thought of as operations between two sets, where records with the same key are combined and records missing in one set are either discarded or included as NULL values.\n",
    "\n",
    "![join types](images/joins.gif)\n",
    "\n",
    "Join Types:\n",
    "- **INNER JOIN:** Returns all rows when there is at least one match in BOTH tables\n",
    "- **LEFT JOIN:** Return all rows from the left table, and the matched rows from the right table\n",
    "- **RIGHT JOIN:** Return all rows from the right table, and the matched rows from the left table\n",
    "- **FULL JOIN:** Return all rows when there is a match in ONE of the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sql join types](images/sql-joins.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order ID is our matching feature that we can use to merge.\n",
    "\n",
    "Lets Checkout all the ways we can merge these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Practice inner joining\n",
    "\n",
    "The most common type of join is: `SQL INNER JOIN` (simple join). An `SQL INNER JOIN` returns all rows from multiple tables where the join condition is met. \n",
    "\n",
    "If we `INNER JOIN` on \"Id\", this takes the intersection of the two tables, excluding the rows for which CustomerID is null in EITHER of the two tables.\n",
    "\n",
    "Essentially, only matching pairs of Order Id's from both Datasets will be taken.\n",
    "\n",
    "**Select Make, MPG, Horsepower, and Year**:\n",
    "- You will need to `INNER JOIN` the `car_names` and `car_data` tables on the `Id` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Practice left joining\n",
    "\n",
    "The `LEFT JOIN` keyword returns all rows from the left table (table1), with the matching rows in the right table (table2). The result is NULL in the right side when there is no match.\n",
    "\n",
    "**Select Make, MPG, Horsepower, and Year**\n",
    "- `SELECT FROM` the `car_names` table\n",
    "- `LEFT JOIN` the `car_data` table by `Id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Right joins and Full Outer Joins (unsupported)\n",
    "\n",
    "> **No exercises for RIGHT and FULL OUTER because they are not supported in this relation.**\n",
    "\n",
    "The `RIGHT JOIN` keyword would all rows from the right table (table2), with the matching rows in the left table (table1). The result is NULL in the left side when there is no match.\n",
    "\n",
    "The `FULL OUTER JOIN` keyword returns all rows from the left table (table1) and from the right table (table2). The `FULL OUTER JOIN` keyword combines the result of both `LEFT` and `RIGHT` joins. In this case we could have NULL values on both sides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addtional resources\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit long winded, but good resources as far as explaining Pandas functions from a SQL programmers perspective:\n",
    "(The opposite of us.)\n",
    "\n",
    "Pydata Video:\n",
    "https://www.youtube.com/watch?v=1uVWjdAbgBg\n",
    "\n",
    "Assciated GitHub Repo:\n",
    "https://github.com/gjreda/pydata2014nyc/tree/master/data\n",
    "\n",
    "\n",
    "\n",
    "Pandas Merge, Join and Concatenate\n",
    "http://pandas.pydata.org/pandas-docs/stable/merging.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "## Practice Data Format Transformations: \"Long\" vs. \"Wide\" Format\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab you will practice going between long and wide formats in pandas, getting deeper into `melt`, `pivot_tables`, and the pitfalls of hierarchical indices than we covered in the lesson.\n",
    "\n",
    "\n",
    "Recall that **long format** has:\n",
    "\n",
    "- Potentially multiple \"id\" (identification) columns.\n",
    "- Variable:value column pairs that match a variable key to a value (in the simple case, a single variable column and a single value column).\n",
    "- The \"variable\" column corresponds to the multiple variable columns in your wide format data. Now, instead of a column for each variable, you have a row for each variable:value pair, per id. \n",
    "- This is a standard format in SQL databases because it is appropriate for joining different tables together by keys.\n",
    "\n",
    "And **wide format:**\n",
    "\n",
    "- There are multiple ID _and_ value columns. In other words, there is a column for every \"variable\" with its own unique values.\n",
    "- The format has both the conceptual simplicity of a single column of values per variable and a more compact matrix.\n",
    "- Is not useful for SQL-style operations: it can make it much harder or even impossible to join tables together on a value.\n",
    "- Can be more useful in pandas when you need to preform operations on variables **across columns**. For example, multiplying columns together.\n",
    "- It is the most commonly the format that you will put the data in when you are ready to perform modeling (with some exceptions). When we get into modeling next week I will explain why.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A: Humor styles dataset\n",
    "\n",
    "We are going to explore a dataset where people answered a questionnaire on their \"humor styles\", which tries to get at differences in people's sense of humor and their relationship with humor.\n",
    "\n",
    "---\n",
    "\n",
    "### A.1: The 32 questions\n",
    "\n",
    "Subjects answered **32** different questions outlined below:\n",
    "\n",
    "1. I usually don't laugh or joke with other people.\n",
    "2. If I feel depressed, I can cheer myself up with humor.\n",
    "3. If someone makes a mistake, I will tease them about it.\n",
    "4. I let people laugh at me or make fun of me at my expense more than I should.\n",
    "5. I don't have to work very hard to make other people laugh. I am a naturally humorous person.\n",
    "6. Even when I'm alone, I am often amused by the absurdities of life.\n",
    "7. People are never offended or hurt by my sense of humor.\n",
    "8. I will often get carried away in putting myself down if it makes family or friends laugh.\n",
    "9. I rarely make other people laugh by telling funny stories about myself.\n",
    "10. If I am feeling upset or unhappy I usually try to think of something funny about the situation to make myself feel better.\n",
    "11. When telling jokes or saying funny things, I am usually not concerned about how other people are taking it.\n",
    "12. I often try to make people like or accept me more by saying something funny about my own weaknesses, blunders, or faults.\n",
    "13. I laugh and joke a lot with my closest friends.\n",
    "14. My humorous outlook on life keeps me from getting overly upset or depressed about things.\n",
    "15. I do not like it when people use humor as a way of criticizing or putting someone down.\n",
    "16. I don't often say funny things to put myself down.\n",
    "17. I usually don't like to tell jokes or amuse people.\n",
    "18. If I'm by myself and I'm feeling unhappy, I make an effort to think of something funny to cheer myself up.\n",
    "19. Sometimes I think of something that is so funny that I can't stop myself from saying it, even if it is not appropriate for the situation.\n",
    "20. I often go overboard in putting myself down when I am making jokes or trying to be funny.\n",
    "21. I enjoy making people laugh.\n",
    "22. If I am feeling sad or upset, I usually lose my sense of humor.\n",
    "23. I never participate in laughing at others even if all my friends are doing it.\n",
    "24. When I am with friends or family, I often seem to be the one that other people make fun of or joke about.\n",
    "25. I donít often joke around with my friends.\n",
    "26. It is my experience that thinking about some amusing aspect of a situation is often a very effective way of coping with problems.\n",
    "27. If I don't like someone, I often use humor or teasing to put them down.\n",
    "28. If I am having problems or feeling unhappy, I often cover it up by joking around, so that even my closest friends don't know how I really feel.\n",
    "29. I usually can't think of witty things to say when I'm with other people.\n",
    "30. I don't need to be with other people to feel amused. I can usually find things to laugh about even when I'm by myself.\n",
    "31. Even if something is really funny to me, I will not laugh or joke about it if someone will be offended.\n",
    "32. Letting others laugh at me is my way of keeping my friends and family in good spirits.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2: Response codes\n",
    "\n",
    "For each question, there are 5 possible response codes (\"likert scale\") that correspond to different answers. There is also a code that indicates there is no response for that subject.\n",
    "\n",
    "    1 == \"Never or very rarely true\"\n",
    "    2 == \"Rarely true\"\n",
    "    3 == \"Sometimes true\"\n",
    "    4 == \"Often true\"\n",
    "    5 == \"Very often or always true\n",
    "    [-1 == Did not select an answer]\n",
    "\n",
    "---\n",
    "\n",
    "[For more info: https://en.wikipedia.org/wiki/Humor_styles]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B: Load modules\n",
    "\n",
    "Let's load the standard modules we always use. None of these are new to you.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data modules\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# plotting modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# make sure charts appear in the notebook:\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## C: Loading and examining the data\n",
    "\n",
    "The dataset is stored in your **```datasets/humor_styles```** directory.\n",
    "\n",
    "The dataset is called **```hsq_data.csv```**. \"hsq\", as you might expect, stands for \"humor styles questionnaire.\n",
    "\n",
    "[There is also a file called **```hsq_codebook.txt```** which is a text file that contains the information I detailed above. You can examine it if you like.]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1: Create path string and load into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hsq_path = './datasets/hsq_data.csv'\n",
    "\n",
    "hsq = pd.read_csv(hsq_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### C.2 Look at the header.\n",
    "\n",
    "Let's make sure it looks like what we expect and the data didn't load in incorrectly. This is, of course, always good practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>affiliative</th>\n",
       "      <th>selfenhancing</th>\n",
       "      <th>agressive</th>\n",
       "      <th>selfdefeating</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10    ...     Q30  Q31  Q32  \\\n",
       "0   2   2   3   1   4   5   4   3   4    3    ...       4    2    2   \n",
       "1   2   3   2   2   4   4   4   3   4    3    ...       4    3    1   \n",
       "2   3   4   3   3   4   4   3   1   2    4    ...       5    4    2   \n",
       "3   3   3   3   4   3   5   4   3  -1    4    ...       5    3    3   \n",
       "4   1   4   2   2   3   5   4   1   4    4    ...       5    4    2   \n",
       "\n",
       "   affiliative  selfenhancing  agressive  selfdefeating  age  gender  accuracy  \n",
       "0          4.0            3.5        3.0            2.3   25       2       100  \n",
       "1          3.3            3.5        3.3            2.4   44       2        90  \n",
       "2          3.9            3.9        3.1            2.3   50       1        75  \n",
       "3          3.6            4.0        2.9            3.3   30       2        85  \n",
       "4          4.1            4.1        2.9            2.0   52       1        80  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the head it's apparent we have **32 columns for each question**, but if we scroll over to the right we can see that there are **7 columns of subject properties**.\n",
    "\n",
    "What are these properties? Some are clear and some are not.\n",
    "\n",
    "#### Styles of humor:\n",
    "\n",
    "1. **affiliative**\n",
    "    - The style of humor used to enhance one's relationships with others in a positive and benevolent way. \n",
    "2. **selfenhancing** \n",
    "    - The style of humor related to having a good-natured attitude toward life, having the ability to laugh at yourself, your circumstances and the idiosyncrasies of life in constructive, non-detrimental manner.\n",
    "3. **aggressive** \n",
    "    - The style of humor that is potentially detrimental towards others. This type of humor is characterized by the use of sarcasm, put-downs, teasing, criticism, ridicule, and other types of humor used at the expense of others.   \n",
    "4. **selfdefeating** \n",
    "    - The style of humor characterized by the use of potentially detrimental humor towards the self in order to gain approval from others. Individuals high in this dimension engage in self-disparaging humor in which laughter is often at their own expense.\n",
    "    \n",
    "These are dimensions of humor calculated from the question responses. \n",
    "\n",
    "- The two positive dimensions of humore are: **affiliative** and **selfenhancing**. \n",
    "- The two _(purportedly)_ negative dimensions of humor are: **aggressive** and **selfdefeating**.\n",
    "\n",
    "We are going to calculate these manually later to practice column-wise operations in pandas.\n",
    "\n",
    "---\n",
    "\n",
    "#### Demographics and self-reported accuracy\n",
    "\n",
    "The demographic columns are:\n",
    "\n",
    "- **age**\n",
    "- **gender**\n",
    "    - 1 == male\n",
    "    - 2 == female\n",
    "    - 3 == other\n",
    "\n",
    "Demographics are great to have for each subject in a dataset. We will see the reasons for this later when we start doing regressions and classification.\n",
    "\n",
    "The **accuracy** column is the self-reported accuracy of the questions by the subjects. It is how accurate they thought their answers were on a scale from 0 to 100.\n",
    "\n",
    "**If a subject entered 0 for accuracy, this actually means they did not want to be included in research.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### C.3: Data shape\n",
    "\n",
    "Lets start to take a look at our data. Print out the shape of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### C.4: Describe the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.1** Print out the names of the columns. You can see that aggressive is misspelled \"agressive\". Replace that column specifically using the ```.rename()``` built-in function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.2** Use the describe built-in function to look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.3** The maximum age is 44849, which is obviously impossible. Clearly there was at least 1 subject that is incorrectly entering their age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.4** Calculate and print just the standard deviation for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.5**\n",
    "\n",
    "Three examples of potentially bad data in this dataset:\n",
    "\n",
    "1. Questions have different standard deviations, but we know the range for the questions is restricted. This means that for the questions with **higher standard deviation** there is **more variability of responses**. \n",
    "2. The standard deviation for age is 1371, which is higher than any possible age range. This is an example of how outliers screw with a lot of statistical measures.\n",
    "3. The standard deviation is lower for the humor style columns. People's values for these attributes are closer together, on average (but keep in mind this might just be because the range is \"shrunk\", which is why it is important to look at both and plot. There are also -1s in the questions that can skew the answers' distributions, as we will see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.6** Using seaborn, plot the distribution for Q15 and plot the distribution for aggressive\n",
    "\n",
    "[Note: you can set ```sns.set(rc={\"figure.figsize\": (12, 12)})``` entered before the distribution plot will set the figure size to 12x12 instead of using the `fig = plt.figure(figsize=(12,12))` pattern. Just another way to do the same thing, use whichever you prefer.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.7** Based on the plots it looks like the calculation of the aggressive style lowers the variability, based on the \"tighter\" distribution. Then again, the question distribution is far from a normal distribution, and so the standard deviation measure is not that descriptive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D: Convert the data from \"wide\" to \"long\"\n",
    "\n",
    "### D.1: Make the question columns clearer\n",
    "\n",
    "**D.1.1** Before we transform our DataFrame to long format, we should make the questions more descriptive so that we know what they are referring to. Use the provided dictionary of question numbers and names to transform the column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_change = {\n",
    "    'Q1':'usually_dont_laugh',\n",
    "    'Q2':'if_depressed_use_humor',\n",
    "    'Q3':'tease_others_mistakes',\n",
    "    'Q4':'let_others_laugh_at_me',\n",
    "    'Q5':'make_others_laugh_easy',\n",
    "    'Q6':'when_alone_amused',\n",
    "    'Q7':'my_humor_never_offensive',\n",
    "    'Q8':'use_self_deprecation',\n",
    "    'Q9':'rarely_make_laugh_stories',\n",
    "    'Q10':'if_upset_use_humor',\n",
    "    'Q11':'dont_care_impact_jokes',\n",
    "    'Q12':'self_deprecate_to_befriend',\n",
    "    'Q13':'laugh_alot_with_friends',\n",
    "    'Q14':'humorous_outlook_improves_mood',\n",
    "    'Q15':'dislike_mean_humor',\n",
    "    'Q16':'dont_self_deprecate',\n",
    "    'Q17':'dont_like_telling_jokes',\n",
    "    'Q18':'when_alone_try_laugh',\n",
    "    'Q19':'joke_when_inappropriate',\n",
    "    'Q20':'harshly_self_deprecate',\n",
    "    'Q21':'enjoy_making_others_laugh',\n",
    "    'Q22':'if_sad_cant_laugh',\n",
    "    'Q23':'never_use_mean_humor',\n",
    "    'Q24':'friends_often_tease_me',\n",
    "    'Q25':'dont_often_joke',\n",
    "    'Q26':'humor_coping_mechanism',\n",
    "    'Q27':'tease_disliked_people',\n",
    "    'Q28':'hide_unhappiness_humor',\n",
    "    'Q29':'cant_think_witty_things',\n",
    "    'Q30':'dont_need_others_amused',\n",
    "    'Q31':'if_mean_wont_laugh',\n",
    "    'Q32':'allow_others_tease_me'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.1.2** Print out the columns and take a look at the header to make sure the columns were renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### D.2: Add a subject ID column\n",
    "\n",
    "We have an index which identifies the rows, but we are going to want a column that is the ID for each subject so that we can keep track of which rows correspond to which subject.\n",
    "\n",
    "If this is not clear, don't worry. The reason we are doing this will become clear when we look at the long-form data visually.\n",
    "\n",
    "**D.2.1** Create an \"ID\" array that is the length of the rows in our data and where each element is unique.\n",
    "\n",
    "[NOTE: Don't call this variable \"id\", as this is reserved. In jupyter notebook, when a variable you are typing gets colored green, you should make it a different name as that is a reserved name.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.2.2** Add a new column to your dataset that is the values of this subject_ids array called \"subject_id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### D.3: Transform the data to long format\n",
    "\n",
    "We are now going to transform our dataset from **wide** to **long** format.\n",
    "\n",
    "The pandas function to convert a wide dataset to a long dataset is **```pd.melt()```**\n",
    "\n",
    "Here is an example call of the function for a made-up dataset:\n",
    "\n",
    "```python\n",
    "id_theft_long = pd.melt(id_theft_wide,\n",
    "                        id_vars=['full_name','birth_date'],\n",
    "                        value_vars=['ccv','zip_code','credit_card_number','pin','ssn'],\n",
    "                        var_name='personal_info',\n",
    "                        value_name='info_value')\n",
    "```\n",
    "\n",
    "So, what are the inputs to this function?\n",
    "\n",
    "- **```id_theft_wide```:** this is my wide format dataset with peoples personal info.\n",
    "- **```id_vars```:** these are the columns that are _already identifiers_ or can otherwise not be in value_vars because it is a different data type.\n",
    "- **```value_vars```:** these are the columns that are going to be now represented in a single value column.\n",
    "- **```var_name```:** this is the name of the new, single column that will have the identifiers for each value by row. _The value_var columns are now represented in a single column._\n",
    "- **```value_name```:** this is the name of the new, single column that has the values from the value_vars columns.\n",
    "\n",
    "**D.3.1** Convert your dataset to long format assigned to a new DataFrame.\n",
    "\n",
    "- Your id_vars will be:\n",
    "    - subject_id\n",
    "    - age\n",
    "    - gender\n",
    "- Your ```value_vars``` will be the names of your question, accuracy, and four humor styles columns.\n",
    "- Make ```var_name``` \"variable\"\n",
    "- Make ```value_name``` \"value\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.3.2** Look at the header. Print the shape of the long DataFrame as well as the unique values in the \"variable\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.3.3** Print the entire subset of the DataFrame where ```subject_id == 10```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.3.4**\n",
    "Why is the row index for the subset increasing, but there is such a big difference between them for subject 10?\n",
    "\n",
    "The ```melt()``` function is not putting the long DataFrame in order of subject_id. It is ordering the DataFrame first by one of the other variables. Because of that, the different rows that correspond to subject 10 are spread out across the DataFrame.\n",
    "\n",
    "This is why it is important to add the \"subject_id\" column prior to converting to long format and use it as an id column. Without it we would not know which rows corresponded to which subjects after converting to long format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.3.5** Figure out a way to have the index ordered by subject_id. Google it if you need to. Reset the index of the sorted dataframe and drop the old index with `drop=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## E: Clean dataset and transform variables\n",
    "\n",
    "Transformation and manipulation of variables within subsets of your data is an essential data science skill!\n",
    "\n",
    "Cleaning is also essential. Cleaning data means removing \"bad\" data or any data that should be excluded from your analyses.\n",
    "\n",
    "### E.1: Convert the gender column to a string representation\n",
    "\n",
    "Recall that:\n",
    "    \n",
    "    1 == 'male'\n",
    "    2 == 'female'\n",
    "    3 == 'other'\n",
    "\n",
    "Let's make gender more readable. Convert the numeric gender column to a string column with the gender labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### E.2: Removing subjects from the dataset\n",
    "\n",
    "**E.2.1** Users that did not respond to certain questions are going to have potentially unreasonable values for their humor style ratings. \n",
    "\n",
    "Find the users that responded ```-1``` on any of the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.2.2** Remove all rows from the datasets corresponding to the bad users.\n",
    "\n",
    "HINTS:\n",
    "    \n",
    "- The **```~```** operator can invert a logical condition/boolean array.\n",
    "- The **```.isin()```** built-in function takes a list of values and returns a boolean array that indicates whether any of the Series or DataFrame values were a member of the list.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.2.3** Subjects who entered 0 for accuracy are actually requesting to not be part of the research. Respecting their wishes, check if any subjects entered 0 for accuracy and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.2.4** Find the subjects that reported an age over 100 and remove them, because they're lying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### E.3: Transform variables (invert some)\n",
    "\n",
    "Some of the scales need to be reversed. We will transform variables so that the valence of the 1-5 likert scale is always going from negative valence to positive valence.\n",
    "\n",
    "For example the scale for this question is already correctly rated from 1 to 5:\n",
    "\n",
    "    Even if I'm by myself, I'm often amused by the absurdity of life.\n",
    "    \n",
    "And this is one that needs to be reversed, since the 1 value actually corresponds to a positive humor style:\n",
    "\n",
    "    I usually don't laugh or joke around much with other people.\n",
    "    \n",
    "Below is a list of the questions that need to be inverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverted_questions = ['usually_dont_laugh',\n",
    "                      'tease_others_mistakes',\n",
    "                      'let_others_laugh_at_me',\n",
    "                      'rarely_make_laugh_stories',\n",
    "                      'use_self_deprecation',\n",
    "                      'tease_disliked_people',\n",
    "                      'cant_think_witty_things',\n",
    "                      'allow_others_tease_me',\n",
    "                      'harshly_self_deprecate',\n",
    "                      'dont_often_joke',\n",
    "                      'if_sad_cant_laugh',\n",
    "                      'dont_like_telling_jokes',\n",
    "                      'dont_care_impact_jokes',\n",
    "                      'self_deprecate_to_befriend',\n",
    "                      'friends_often_tease_me',\n",
    "                      'joke_when_inappropriate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.3.1** Write a function that will accept a score value and \"invert\" the score. That is to say:\n",
    "\n",
    "    1 -> 5\n",
    "    2 -> 4\n",
    "    3 -> 3\n",
    "    4 -> 2\n",
    "    5 -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.3.2** Apply the score inverter function to the values where the variable is in the ```inverted_question``` list, reassigning the ```value``` column at those locations.\n",
    "\n",
    "Don't forget about the ```.isin()``` function for Series as well as the ```.map()``` or ```.apply()``` functions for element-wise operations on a Series!\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.isin.html\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.Series.apply.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## F: Transforming the dataset back to wide format\n",
    "\n",
    "Now we will transform the DataFrame in long format back to wide format.\n",
    "\n",
    "We are going to be using the powerful **```pd.pivot_table()```** function. \n",
    "\n",
    "---\n",
    "\n",
    "### F.1: Use pd.pivot_table() to re-widen your data\n",
    "\n",
    "The ```pd.pivot_table()``` function takes a variety of arguments. For now, lets just set the keyword arguments and corresponding values outlined below:\n",
    "\n",
    "- **data** The first argument is your DataFrame you are going to pivot.\n",
    "\n",
    "- **index** is the key or keys to group by along the pivot table indices, or rows. These \"keys\" are column names in your DataFrame:\n",
    "\n",
    "```python\n",
    "index = ['subject_id','age','gender']\n",
    "```\n",
    "\n",
    "- **columns** is the key or keys to group by along the pivot table columns. These are also column names or a name:\n",
    "\n",
    "```python\n",
    "columns = ['variable']\n",
    "```\n",
    "\n",
    "- **values** is the key or keys that are the values to \"aggregate\". More on aggregation soon, but don't worry about it right now.\n",
    "\n",
    "```python\n",
    "values = 'value'\n",
    "```\n",
    "\n",
    "- **aggfunc** should be the count, which can be the function `len`\n",
    "\n",
    "```python\n",
    "aggfunc = len\n",
    "```\n",
    "\n",
    "**F.1.1** Create a new widened DataFrame from your long data using the specified keyword arguments above. Print out the head and the shape as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.1.2 Reset the index and turn the data into long format\n",
    "\n",
    "The long form melted dataset should have 3 columns: gender, variable, and count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.1.3 Merge the count long dataset into the full long dataset\n",
    "\n",
    "Merge this small counts by gender and variable dataframe with the original full long dataframe.\n",
    "\n",
    "You have two key variables in the counts dataframe that we need to match with in the full long dataframe.\n",
    "\n",
    "Your code would look something like this:\n",
    "\n",
    "```python\n",
    "hsq_long_merged = hsq_long.merge(hsq_count_long, on=['gender','variable'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.1.4 Use the pivot table function to calculate the mean of both the original values and the counts by gender and age across variables\n",
    "\n",
    "Example code could be something like this:\n",
    "\n",
    "```python\n",
    "value_count_means = pd.pivot_table(hsq_long_merged,\n",
    "                                   index=['gender','age'],\n",
    "                                   columns=['variable'],\n",
    "                                   values=['value', 'count'],\n",
    "                                   aggfunc=np.mean)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### F.2: Understanding the MultiIndex\n",
    "\n",
    "The MultiIndex at first appears daunting and confusing. What is it? How do we use it?\n",
    "\n",
    "**F.2.1** Print out the columns of your wide value and counts means dataframe you created in the question prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns before was just a list of the column names, but now there are three attributes:\n",
    "\n",
    "- **levels** is the list of lists that contains the hierarchy of header labels\n",
    "- **labels** is the list of lists that specifies which level label goes in which position at each hierarchical level\n",
    "- **names** are the names of the hierarchical header levels\n",
    "\n",
    "**F.2.2** Print out the ```.columns.names``` property specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name for the second level is \"variable\", and the first (top) level has ```None```: no name.\n",
    "\n",
    "Why is the top level ```None```? \n",
    "\n",
    "The name \"variable\" is indicating the category, so to speak, of the bottom level header labels. Looking at the ```.head()``` printout, you can see that the \"variable\" is just to the left of all the bottom level headers. The **name of that level is \"variable\"** (which is the column they were pulled out of in the long data).\n",
    "\n",
    "The upper level, \"value\", has no name because there aren't tiers above it and pandas chooses to not give it a name! \n",
    "\n",
    "The names are just convenience anyway, since you **index by labels**.\n",
    "\n",
    "---\n",
    "\n",
    "Still confused? Think of it this way: the \"value\" label at the top spans all the columns and corresponds to the values in the cells of the columns. \n",
    "\n",
    "Remember how the variable and value columns in the long data looked?\n",
    "\n",
    "```\n",
    "variable       value\n",
    "--------       -----\n",
    "accuracy       100\n",
    "accuracy       80\n",
    "selfdefeating  2.2\n",
    "selfenhancing  3.1\n",
    "selfdefeating  1.1\n",
    "...\n",
    "```\n",
    "\n",
    "**\"value\" is the top level in the header hierarchy because the unique \"variable\" column items correspond to a subset of the \"value\" column numbers.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.2.3** Print out the ```.index.names``` property of your wide data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is `gender` and `age`. These corresponds to the leftmost part of the ```.head()``` printout, which are the row indices (also hierarchical in this case). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### F.3: Indexing with a MultiIndex: alternative methods\n",
    "\n",
    "pandas provides many different ways you can index your DataFrame when it has a MultiIndex. I am just going to go over three, which are the ones I find most intuitive in order:\n",
    "\n",
    "1. Using **```.xs()```** which is the \"cross-section\" indexing function\n",
    "2. Using a **```pd.IndexSlice```** object\n",
    "3. Using the **```.query()```** function\n",
    "\n",
    "Let's start with the cross-section function.\n",
    "\n",
    "**F.3.1** Type the following (replacing value_count_means with your wide DataFrame name):\n",
    "\n",
    "```python\n",
    "value_count_means.xs(3, level='gender')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.3.2** the .xs() function is pulling out value 20 at the index level age. So, it is subsetting the data to be everything that corresponds to age == 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.3.3** \n",
    "\n",
    "First remove the `value` column index, making the columns non-hierarchical.\n",
    "\n",
    "Then type the following python and explain what is happening and why:\n",
    "\n",
    "```python\n",
    "value_count_means.xs((21, 'male'), level='age', axis=0, drop_level=False)[['aggressive','affiliative']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.3.3** Cross section is pulling out along multiple indices using lists/tuples for the section and levels argument. The axis=0 part is saying run this on the row indices (axis=1 would mean your parameters are referring to column indices). drop_levels=False is keeping the indices in the return value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**F.3.4** Let's try out the `.query()` function for DataFrames. Query is very nice because it allows us to enter in expressions as strings that are very intuitive.\n",
    "\n",
    "Try these query examples out below:\n",
    "\n",
    "```dislike_mean_humor``` scores for males only aged 18, 25, or 30:\n",
    "\n",
    "```python\n",
    "value_count_means.query('(gender == male) and (age in [18, 25, 30)')[['dislike_mean_humor']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get very complicated with the conditionals.\n",
    "\n",
    "Try a query where where aggressive, affiliative, selfdefeating, and selfenhancing multiplied by each other are less than the subject's age (and subset to those humor descriptor columns too).\n",
    "\n",
    "```python\n",
    "value_count_means.query('(aggresive*affiliative*selfenhancing*selfdefeating) > age')[['aggresive','affiliative','selfenhancing','selfdefeating']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "More on MultiIndex and advanced indexing below. **HIGHLY RECOMMENDED READING!**\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/advanced.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### F.4 Flattening a MultiIndex DataFrame\n",
    "\n",
    "MultiIndex is great and quite powerful, but if you are feeling overwhelmed and want to go back to the standard indexed data, you can.\n",
    "\n",
    "You can use **```.reset_index()```** and also **`.to_records()`** to get the same eventual result.\n",
    "\n",
    "Try it out on the wide data below with:\n",
    "\n",
    "```python\n",
    "value_count_means.reset_index()\n",
    "pd.DataFrame(value_count_means.to_records())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of reset_index, your index is now called \"variable\". with to_records(), the index is just the standard integer labels for rows. All the hierarchical indices have been flattened down into columns.\n",
    "\n",
    "check out the ```.columns```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
